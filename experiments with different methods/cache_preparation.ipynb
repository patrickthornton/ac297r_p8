{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git'\n"
      ],
      "metadata": {
        "id": "kU_F6qfXsR-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "metadata": {
        "id": "_q0N1YoBQE-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JdPgd9_sPo0"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "\n",
        "BASE_DIR        = \"/content/drive/MyDrive\"\n",
        "SAMPLE_JSON     = os.path.join(BASE_DIR, \"sample_list.json\")\n",
        "HUMAN_NPZ_PATH  = os.path.join(BASE_DIR, \"human_mask_cache_224.npz\")\n",
        "REF_NPZ_PATH    = os.path.join(BASE_DIR, \"ref_mask_cache_224.npz\")\n",
        "REF_LABELS      = [\"a white ball.\", \"a dark paper.\"]\n",
        "SAMPLE_COUNT    = None\n",
        "OUT_W, OUT_H    = 224, 224\n",
        "\n",
        "def letterbox_mask(mask: np.ndarray, new_size=(OUT_W, OUT_H)):\n",
        "    h, w = mask.shape\n",
        "    nw, nh = new_size\n",
        "    scale = min(nw / w, nh / h)\n",
        "    rw, rh = int(w * scale), int(h * scale)\n",
        "    mask_resized = cv2.resize(mask, (rw, rh), interpolation=cv2.INTER_NEAREST)\n",
        "    top   = (nh - rh) // 2\n",
        "    left  = (nw - rw) // 2\n",
        "    out = np.zeros((nh, nw), dtype=mask.dtype)\n",
        "    out[top:top+rh, left:left+rw] = mask_resized\n",
        "    return out\n",
        "\n",
        "def main():\n",
        "    with open(SAMPLE_JSON, \"r\") as f:\n",
        "        all_samples = json.load(f)\n",
        "\n",
        "    if SAMPLE_COUNT is not None:\n",
        "        samples = random.sample(all_samples, min(SAMPLE_COUNT, len(all_samples)))\n",
        "    else:\n",
        "        samples = all_samples\n",
        "\n",
        "    cfg = get_cfg()\n",
        "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "    human_predictor = DefaultPredictor(cfg)\n",
        "\n",
        "    ref_detector = pipeline(\n",
        "        task=\"zero-shot-object-detection\",\n",
        "        model=\"IDEA-Research/grounding-dino-tiny\",\n",
        "        device=0 if torch.cuda.is_available() else -1\n",
        "    )\n",
        "\n",
        "    human_cache = {}\n",
        "    ref_cache   = {}\n",
        "\n",
        "    for s in tqdm(samples, desc=\"Building 224Ã—224 mask cache (letterbox)\"):\n",
        "        for p in s[\"img_paths\"][:2]:\n",
        "            if p in human_cache:\n",
        "                continue\n",
        "            if not os.path.exists(p):\n",
        "                print(\"Missing file:\", p)\n",
        "                continue\n",
        "\n",
        "            pil = Image.open(p).convert(\"RGB\")\n",
        "            pil = ImageOps.exif_transpose(pil)\n",
        "            arr = np.array(pil)\n",
        "            H, W = arr.shape[:2]\n",
        "\n",
        "            out = human_predictor(cv2.cvtColor(arr, cv2.COLOR_RGB2BGR))\n",
        "            inst = out[\"instances\"]\n",
        "            hm = np.zeros((H, W), dtype=np.uint8)\n",
        "            if len(inst) > 0:\n",
        "                cls = inst.pred_classes.cpu().numpy()\n",
        "                ids = np.where(cls == 0)[0]\n",
        "                if len(ids) > 0:\n",
        "                    scores = inst.scores.cpu().numpy()[ids]\n",
        "                    idx = ids[scores.argmax()]\n",
        "                    if inst.has(\"pred_masks\"):\n",
        "                        hm = inst.pred_masks[idx].cpu().numpy().astype(np.uint8)\n",
        "                    else:\n",
        "                        y0, x0, y1, x1 = inst.pred_boxes[idx].tensor.cpu().numpy()[0]\n",
        "                        hm[int(y0):int(y1), int(x0):int(x1)] = 1\n",
        "            human_cache[p] = letterbox_mask(hm)\n",
        "\n",
        "            dets = ref_detector(pil, candidate_labels=REF_LABELS, threshold=0.7)\n",
        "            det_map = {d[\"label\"].rstrip('.').lower(): d for d in dets}\n",
        "            for lbl in REF_LABELS:\n",
        "                k = f\"{p}|{lbl.rstrip('.').lower()}\"\n",
        "                rm = np.zeros((H, W), dtype=np.uint8)\n",
        "                d  = det_map.get(lbl.rstrip('.').lower())\n",
        "                if d:\n",
        "                    x0, y0 = int(d[\"box\"][\"xmin\"]), int(d[\"box\"][\"ymin\"])\n",
        "                    x1, y1 = int(d[\"box\"][\"xmax\"]), int(d[\"box\"][\"ymax\"])\n",
        "                    rm[y0:y1, x0:x1] = 1\n",
        "                ref_cache[k] = letterbox_mask(rm)\n",
        "\n",
        "    np.savez_compressed(HUMAN_NPZ_PATH, **human_cache)\n",
        "    np.savez_compressed(REF_NPZ_PATH,   **ref_cache)\n",
        "\n",
        "    print(\"Saved human masks to\", HUMAN_NPZ_PATH, \"entries:\", len(human_cache))\n",
        "    print(\"Saved ref masks to\", REF_NPZ_PATH, \"entries:\", len(ref_cache))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "Ra6UvCAr1Cp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "human_npz_path = '/content/drive/MyDrive/human_mask_cache_224.npz'\n",
        "ref_npz_path   = '/content/drive/MyDrive/ref_mask_cache_224.npz'\n",
        "\n",
        "human_masks = np.load(human_npz_path, allow_pickle=True)\n",
        "ref_masks   = np.load(ref_npz_path, allow_pickle=True)\n",
        "\n",
        "keys = list(human_masks.files)\n",
        "selected = random.sample(keys, 5)\n",
        "\n",
        "for key in selected:\n",
        "    img = Image.open(key).convert('RGB')\n",
        "    mask_h = human_masks[key]\n",
        "    ref_keys = [k for k in ref_masks.files if k.startswith(key + '|')]\n",
        "    n_cols = 2 + len(ref_keys)\n",
        "    fig, axes = plt.subplots(1, n_cols, figsize=(4*n_cols, 4))\n",
        "    axes[0].imshow(img)\n",
        "    axes[0].axis('off')\n",
        "    axes[0].set_title('Original')\n",
        "    axes[1].imshow(mask_h, cmap='gray')\n",
        "    axes[1].axis('off')\n",
        "    axes[1].set_title('Human Mask')\n",
        "    for i, rk in enumerate(ref_keys, start=2):\n",
        "        mask_r = ref_masks[rk]\n",
        "        axes[i].imshow(mask_r, cmap='gray')\n",
        "        axes[i].axis('off')\n",
        "        axes[i].set_title(f'Ref Mask\\n{rk.split(\"|\")[-1]}')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "ZXAcA_LIw65T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}