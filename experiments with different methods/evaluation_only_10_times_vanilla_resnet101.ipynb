{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bIWn6j9DJtMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gCAC9HmxLBq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HkMFYLKQLBox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h_fUyNRJJq9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2TdzRiGJmqL"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "multiprocessing.set_start_method(\"spawn\", force=True)\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageOps\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Optional, Union, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from scipy.stats import ks_2samp, wasserstein_distance\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class LetterboxResize:\n",
        "    def __init__(self, size=(224, 224), fill=(0.485, 0.456, 0.406)):\n",
        "        self.size = size\n",
        "        self.fill = fill\n",
        "    def __call__(self, img):\n",
        "        img = ImageOps.exif_transpose(img)\n",
        "        iw, ih = img.size\n",
        "        w, h = self.size\n",
        "        scale = min(w / iw, h / ih)\n",
        "        nw, nh = int(iw * scale), int(ih * scale)\n",
        "        img = img.resize((nw, nh), Image.BICUBIC)\n",
        "        new_img = Image.new(\"RGB\", self.size, tuple([int(c * 255) for c in self.fill]))\n",
        "        new_img.paste(img, ((w - nw) // 2, (h - nh) // 2))\n",
        "        return new_img\n",
        "\n",
        "class MultiViewBMIDataset(Dataset):\n",
        "    def __init__(self, sample_list, transform=None):\n",
        "        self.samples = sample_list\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.samples[idx]\n",
        "        imgs = []\n",
        "        for path in sample[\"img_paths\"]:\n",
        "            if not os.path.exists(path):\n",
        "                img = Image.new(\"RGB\", (224, 224), (0, 0, 0))\n",
        "            else:\n",
        "                try:\n",
        "                    img = Image.open(path).convert(\"RGB\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error opening image: {path} | {e}\")\n",
        "                    img = Image.new(\"RGB\", (224, 224), (0, 0, 0))\n",
        "            if self.transform is not None:\n",
        "                img = self.transform(img)\n",
        "            imgs.append(img)\n",
        "        bmi = float(sample[\"bmi\"])\n",
        "        return imgs[0], imgs[1], imgs[2], bmi\n",
        "\n",
        "class MultiViewResNet101Baseline(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        \"\"\"\n",
        "        num_classes: number of classes (e.g., 3 BMI bins); regression loss is used.\n",
        "        \"\"\"\n",
        "        super(MultiViewResNet101Baseline, self).__init__()\n",
        "        resnet_path = \"/content/drive/MyDrive/resnet101-63fe2227.pth\"\n",
        "        print(\"Loading ResNet101 weights...\")\n",
        "        base = models.resnet101(weights=None)\n",
        "        state_dict = torch.load(resnet_path, map_location=DEVICE)\n",
        "        base.load_state_dict(state_dict)\n",
        "        print(\"Weights loaded successfully!\")\n",
        "        self.backbone = nn.Sequential(*list(base.children())[:-1])\n",
        "        self.fc_reg = nn.Linear(2048 * 3, 1)\n",
        "        self.fc_cls = nn.Linear(2048 * 3, num_classes)\n",
        "    def forward(self, img1, img2, img3):\n",
        "        def extract(x):\n",
        "            x = self.backbone(x)\n",
        "            return torch.flatten(x, 1)\n",
        "        f1 = extract(img1)\n",
        "        f2 = extract(img2)\n",
        "        f3 = extract(img3)\n",
        "        fused = torch.cat([f1, f2, f3], dim=1)\n",
        "        out_reg = self.fc_reg(fused)\n",
        "        out_cls = self.fc_cls(fused)\n",
        "        return out_reg, out_cls\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    sample_json = \"/content/drive/MyDrive/sample_list.json\"\n",
        "    with open(sample_json, \"r\") as f:\n",
        "        samples = json.load(f)\n",
        "    train_samples = [s for s in samples if s[\"split\"] == \"Training\"]\n",
        "    val_samples = [s for s in samples if s[\"split\"] == \"Validation\"]\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        LetterboxResize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    train_dataset = MultiViewBMIDataset(train_samples, transform=transform)\n",
        "    val_dataset = MultiViewBMIDataset(val_samples, transform=transform)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "    print(f\"Train Dataset Size: {len(train_dataset)}\")\n",
        "    print(f\"Val Dataset Size: {len(val_dataset)}\")\n",
        "\n",
        "    num_epochs = 20\n",
        "    num_runs = 10\n",
        "    results = []\n",
        "\n",
        "    for run in range(num_runs):\n",
        "        print(f\"\\n========== Run {run+1} ==========\")\n",
        "        model = MultiViewResNet101Baseline(num_classes=3).to(DEVICE)\n",
        "        criterion_reg = nn.MSELoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "        for epoch in range(1, num_epochs + 1):\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            start_time = time.time()\n",
        "            for img1, img2, img3, bmi in train_loader:\n",
        "                img1, img2, img3 = img1.to(DEVICE), img2.to(DEVICE), img3.to(DEVICE)\n",
        "                targets = bmi.to(DEVICE).float().unsqueeze(1)\n",
        "                optimizer.zero_grad()\n",
        "                out_reg, _ = model(img1, img2, img3)\n",
        "                loss = criterion_reg(out_reg, targets)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss.item() * targets.size(0)\n",
        "            epoch_loss = running_loss / len(train_dataset)\n",
        "            print(f\"[Run {run+1}] Epoch {epoch}/{num_epochs}, Loss: {epoch_loss:.4f}, Time: {time.time()-start_time:.2f}s\")\n",
        "\n",
        "        model.eval()\n",
        "        all_preds, all_targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for img1, img2, img3, bmi in val_loader:\n",
        "                img1, img2, img3 = img1.to(DEVICE), img2.to(DEVICE), img3.to(DEVICE)\n",
        "                targets = bmi.to(DEVICE).float().unsqueeze(1)\n",
        "                out_reg, _ = model(img1, img2, img3)\n",
        "                all_preds.extend(out_reg.cpu().numpy().flatten().tolist())\n",
        "                all_targets.extend(targets.cpu().numpy().flatten().tolist())\n",
        "        gt_arr = np.array(all_targets)\n",
        "        pred_arr = np.array(all_preds)\n",
        "        try:\n",
        "            r2_val = r2_score(gt_arr, pred_arr)\n",
        "        except Exception as e:\n",
        "            r2_val = 0.0\n",
        "        mae_val = mean_absolute_error(gt_arr, pred_arr)\n",
        "        tolerance = 1.0\n",
        "        tol_rate = np.mean(np.abs(gt_arr - pred_arr) <= tolerance)\n",
        "        error = pred_arr - gt_arr\n",
        "        mean_bias = np.mean(error)\n",
        "        error_std = np.std(error)\n",
        "        try:\n",
        "            ks_val, _ = ks_2samp(gt_arr, pred_arr)\n",
        "            wass_val = wasserstein_distance(gt_arr, pred_arr)\n",
        "        except Exception as e:\n",
        "            ks_val = wass_val = 0.0\n",
        "\n",
        "        print(f\"\\n[Run {run+1}] Validation Metrics:\")\n",
        "        print(f\"R²: {r2_val:.4f}\")\n",
        "        print(f\"MAE: {mae_val:.4f}\")\n",
        "        print(f\"Tolerance Rate (±{tolerance}): {tol_rate*100:.2f}%\")\n",
        "        print(f\"Mean Bias: {mean_bias:.4f}\")\n",
        "        print(f\"Error Std: {error_std:.4f}\")\n",
        "        print(f\"KS: {ks_val:.4f}\")\n",
        "        print(f\"Wasserstein: {wass_val:.4f}\\n\")\n",
        "\n",
        "        results.append({\n",
        "            'r2': r2_val,\n",
        "            'mae': mae_val,\n",
        "            'tol_rate': tol_rate,\n",
        "            'mean_bias': mean_bias,\n",
        "            'error_std': error_std,\n",
        "            'ks': ks_val,\n",
        "            'wasserstein': wass_val\n",
        "        })\n",
        "\n",
        "    r2_vals = [res['r2'] for res in results]\n",
        "    mae_vals = [res['mae'] for res in results]\n",
        "    tol_vals = [res['tol_rate'] for res in results]\n",
        "    mean_bias_vals = [res['mean_bias'] for res in results]\n",
        "    err_std_vals = [res['error_std'] for res in results]\n",
        "    ks_vals = [res['ks'] for res in results]\n",
        "    wass_vals = [res['wasserstein'] for res in results]\n",
        "\n",
        "    print(\"\\n========== Overall Results (10 runs, 20 epochs each) ==========\")\n",
        "    print(f\"R²: Mean = {np.mean(r2_vals):.4f}, Std = {np.std(r2_vals):.4f}\")\n",
        "    print(f\"MAE: Mean = {np.mean(mae_vals):.4f}, Std = {np.std(mae_vals):.4f}\")\n",
        "    print(f\"Tolerance Rate: Mean = {np.mean(tol_vals)*100:.2f}%, Std = {np.std(tol_vals)*100:.2f}%\")\n",
        "    print(f\"Mean Bias: Mean = {np.mean(mean_bias_vals):.4f}, Std = {np.std(mean_bias_vals):.4f}\")\n",
        "    print(f\"Error Std: Mean = {np.mean(err_std_vals):.4f}, Std = {np.std(err_std_vals):.4f}\")\n",
        "    print(f\"KS: Mean = {np.mean(ks_vals):.4f}, Std = {np.std(ks_vals):.4f}\")\n",
        "    print(f\"Wasserstein: Mean = {np.mean(wass_vals):.4f}, Std = {np.std(wass_vals):.4f}\")\n"
      ]
    }
  ]
}