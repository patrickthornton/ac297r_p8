{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bIWn6j9DJtMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gCAC9HmxLBq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HkMFYLKQLBox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h_fUyNRJJq9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2TdzRiGJmqL"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "multiprocessing.set_start_method(\"spawn\", force=True)\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageOps\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Optional, Union, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from scipy.stats import ks_2samp, wasserstein_distance\n",
        "\n",
        "# Mount Google Drive (ensure JSON and images are on Drive)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Global device setting\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Current device:\", DEVICE)\n",
        "\n",
        "# Data Preprocessing: LetterboxResize (consistent with experimental group)\n",
        "class LetterboxResize:\n",
        "    def __init__(self, size=(224, 224), fill=(0.485, 0.456, 0.406)):\n",
        "        self.size = size\n",
        "        self.fill = fill\n",
        "    def __call__(self, img):\n",
        "        # Correct image orientation\n",
        "        img = ImageOps.exif_transpose(img)\n",
        "        iw, ih = img.size\n",
        "        w, h = self.size\n",
        "        scale = min(w / iw, h / ih)\n",
        "        nw, nh = int(iw * scale), int(ih * scale)\n",
        "        img = img.resize((nw, nh), Image.BICUBIC)\n",
        "        new_img = Image.new(\"RGB\", self.size, tuple([int(c * 255) for c in self.fill]))\n",
        "        new_img.paste(img, ((w - nw) // 2, (h - nh) // 2))\n",
        "        return new_img\n",
        "\n",
        "# Dataset definition: MultiViewBMIDataset (2-view version)\n",
        "# Loads the first 2 images and returns BMI as the target\n",
        "class MultiViewBMIDataset(Dataset):\n",
        "    def __init__(self, sample_list, transform=None):\n",
        "        self.samples = sample_list\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.samples[idx]\n",
        "        imgs = []\n",
        "        for path in sample[\"img_paths\"][:2]:\n",
        "            if not os.path.exists(path):\n",
        "                img = Image.new(\"RGB\", (224, 224), (0, 0, 0))\n",
        "            else:\n",
        "                try:\n",
        "                    img = Image.open(path).convert(\"RGB\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error opening image: {path} | {e}\")\n",
        "                    img = Image.new(\"RGB\", (224, 224), (0, 0, 0))\n",
        "            if self.transform is not None:\n",
        "                img = self.transform(img)\n",
        "            imgs.append(img)\n",
        "        bmi = float(sample[\"bmi\"])\n",
        "        return imgs[0], imgs[1], bmi\n",
        "\n",
        "# BMI classification function (3 classes)\n",
        "def get_bmi_class_new(bmi):\n",
        "    if bmi < 17.28:\n",
        "        return 0\n",
        "    elif bmi < 25.57:\n",
        "        return 1\n",
        "    else:\n",
        "        return 2\n",
        "\n",
        "# Model definition: FusedMultiViewBMIModel_2view\n",
        "# Uses ResNet101 to extract 2048-dim features per image (2-view => 4096-dim), then predicts BMI (regression) and BMI class\n",
        "class FusedMultiViewBMIModel_2view(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super().__init__()\n",
        "        resnet_path = \"/content/drive/MyDrive/resnet101-63fe2227.pth\"\n",
        "        print(\"Loading ResNet101 weights...\")\n",
        "        base = models.resnet101(weights=None)\n",
        "        state_dict = torch.load(resnet_path, map_location=DEVICE)\n",
        "        base.load_state_dict(state_dict)\n",
        "        print(\"Weights loaded successfully!\")\n",
        "        self.backbone = nn.Sequential(*list(base.children())[:-1])\n",
        "        self.fc_reg = nn.Linear(4096, 1)\n",
        "        self.fc_cls = nn.Linear(4096, num_classes)\n",
        "    def forward(self, img1, img2):\n",
        "        def extract(x):\n",
        "            x = self.backbone(x)\n",
        "            return torch.flatten(x, 1)\n",
        "        f1 = extract(img1)  # [B, 2048]\n",
        "        f2 = extract(img2)  # [B, 2048]\n",
        "        fused = torch.cat([f1, f2], dim=1)  # [B, 4096]\n",
        "        out_reg = self.fc_reg(fused)\n",
        "        out_cls = self.fc_cls(fused)\n",
        "        return out_reg, out_cls\n",
        "\n",
        "# Training and validation process (includes classification loss)\n",
        "if __name__ == \"__main__\":\n",
        "    # Load sample list JSON\n",
        "    sample_json = \"/content/drive/MyDrive/sample_list.json\"\n",
        "    with open(sample_json, \"r\") as f:\n",
        "        samples = json.load(f)\n",
        "    # Split samples based on \"split\" field (case-sensitive)\n",
        "    train_samples = [s for s in samples if s[\"split\"] == \"Training\"]\n",
        "    val_samples   = [s for s in samples if s[\"split\"] == \"Validation\"]\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        LetterboxResize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    train_dataset = MultiViewBMIDataset(train_samples, transform=transform)\n",
        "    val_dataset = MultiViewBMIDataset(val_samples, transform=transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "    print(f\"Train Dataset Size: {len(train_dataset)}\")\n",
        "    print(f\"Val Dataset Size: {len(val_dataset)}\")\n",
        "\n",
        "    # Experiment settings: different class loss weight factors (vector: [wf, 1, wf])\n",
        "    weight_factors = [1, 2, 3, 5, 8]\n",
        "    num_epochs = 20\n",
        "\n",
        "    # Run experiments for different weight factors\n",
        "    for wf in weight_factors:\n",
        "        print(f\"\\n====== Classification Loss Weight Factor: {wf} (multiply head/tail by {wf}, middle is 1) ======\")\n",
        "        class_weight = torch.tensor([wf, 1.0, wf], dtype=torch.float32, device=DEVICE)\n",
        "        criterion_reg = nn.MSELoss()\n",
        "        criterion_cls = nn.CrossEntropyLoss(weight=class_weight)\n",
        "        model = FusedMultiViewBMIModel_2view(num_classes=3).to(DEVICE)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "        # Training phase\n",
        "        for epoch in range(1, num_epochs+1):\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            start_time = time.time()\n",
        "            for img1, img2, bmi in train_loader:\n",
        "                img1, img2 = img1.to(DEVICE), img2.to(DEVICE)\n",
        "                targets = bmi.to(DEVICE).float().unsqueeze(1)\n",
        "                cls_targets = torch.tensor([get_bmi_class_new(b.item()) for b in bmi],\n",
        "                                             dtype=torch.long, device=DEVICE)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                out_reg, out_cls = model(img1, img2)\n",
        "                loss_reg = criterion_reg(out_reg, targets)\n",
        "                loss_cls = criterion_cls(out_cls, cls_targets)\n",
        "                loss = loss_reg + loss_cls\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss.item() * targets.size(0)\n",
        "            epoch_loss = running_loss / len(train_dataset)\n",
        "            print(f\"Epoch {epoch}/{num_epochs}, Loss: {epoch_loss:.4f}, Time: {time.time()-start_time:.2f}s\")\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        all_preds, all_targets, all_cls_preds, all_cls_targets = [], [], [], []\n",
        "        with torch.no_grad():\n",
        "            for img1, img2, bmi in val_loader:\n",
        "                img1, img2 = img1.to(DEVICE), img2.to(DEVICE)\n",
        "                targets = bmi.to(DEVICE).float().unsqueeze(1)\n",
        "                out_reg, out_cls = model(img1, img2)\n",
        "                all_preds.extend(out_reg.cpu().numpy().flatten().tolist())\n",
        "                all_targets.extend(targets.cpu().numpy().flatten().tolist())\n",
        "                cls_pred = torch.argmax(out_cls, dim=1)\n",
        "                cls_target = torch.tensor([get_bmi_class_new(b.item()) for b in bmi],\n",
        "                                            dtype=torch.long, device=DEVICE)\n",
        "                all_cls_preds.extend(cls_pred.cpu().numpy().tolist())\n",
        "                all_cls_targets.extend(cls_target.cpu().numpy().tolist())\n",
        "        gt_arr = np.array(all_targets)\n",
        "        pred_arr = np.array(all_preds)\n",
        "        try:\n",
        "            r2_val = r2_score(gt_arr, pred_arr)\n",
        "        except Exception as e:\n",
        "            r2_val = 0.0\n",
        "        mae_val = mean_absolute_error(gt_arr, pred_arr)\n",
        "        tol_rate = np.mean(np.abs(gt_arr - pred_arr) <= 1.0)\n",
        "        error = pred_arr - gt_arr\n",
        "        mean_bias = np.mean(error)\n",
        "        error_std = np.std(error)\n",
        "        try:\n",
        "            ks_val, _ = ks_2samp(gt_arr, pred_arr)\n",
        "            wass_val = wasserstein_distance(gt_arr, pred_arr)\n",
        "        except Exception as e:\n",
        "            ks_val = wass_val = 0.0\n",
        "        cls_acc = np.mean(np.array(all_cls_preds) == np.array(all_cls_targets))\n",
        "\n",
        "        print(\"\\nValidation Metrics:\")\n",
        "        print(f\"R²: {r2_val:.4f}\")\n",
        "        print(f\"MAE: {mae_val:.4f}\")\n",
        "        print(f\"Tolerance Rate (±1.0): {tol_rate*100:.2f}%\")\n",
        "        print(f\"Mean Bias: {mean_bias:.4f}\")\n",
        "        print(f\"Error Std: {error_std:.4f}\")\n",
        "        print(f\"KS: {ks_val:.4f}\")\n",
        "        print(f\"Wasserstein: {wass_val:.4f}\")\n",
        "        print(f\"Classification Accuracy: {cls_acc*100:.2f}%\")\n"
      ]
    }
  ]
}