{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRG4S7hI-vzD"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "import multiprocessing\n",
        "multiprocessing.set_start_method(\"spawn\", force=True)\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "from scipy.stats import ks_2samp, wasserstein_distance\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class LetterboxResize:\n",
        "    def __init__(self, size=(224,224), fill=(0,0,0)):\n",
        "        self.size, self.fill = size, fill\n",
        "    def __call__(self, img):\n",
        "        iw, ih = img.size\n",
        "        w, h = self.size\n",
        "        scale = min(w/iw, h/ih)\n",
        "        nw, nh = int(iw*scale), int(ih*scale)\n",
        "        img = img.resize((nw, nh), Image.BICUBIC)\n",
        "        new = Image.new(\"RGB\", self.size, self.fill)\n",
        "        new.paste(img, ((w-nw)//2, (h-nh)//2))\n",
        "        return new\n",
        "\n",
        "class MultiViewBMIDataset3(Dataset):\n",
        "    def __init__(self, samples, transform=None):\n",
        "        self.samples = samples\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "    def __getitem__(self, idx):\n",
        "        s = self.samples[idx]\n",
        "        imgs = []\n",
        "        for p in s[\"img_paths\"]:\n",
        "            if os.path.exists(p):\n",
        "                try:\n",
        "                    img = Image.open(p).convert(\"RGB\")\n",
        "                except:\n",
        "                    img = Image.new(\"RGB\",(224,224),(0,0,0))\n",
        "            else:\n",
        "                img = Image.new(\"RGB\",(224,224),(0,0,0))\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "            imgs.append(img)\n",
        "        bmi = float(s[\"bmi\"])\n",
        "        return imgs[0], imgs[1], imgs[2], torch.tensor(bmi, dtype=torch.float32)\n",
        "\n",
        "def get_bmi_class(b):\n",
        "    if b < 17.28: return 0\n",
        "    if b < 25.57: return 1\n",
        "    return 2\n",
        "\n",
        "class FusedMultiViewBMIModel3(nn.Module):\n",
        "    def __init__(self, view_indices):\n",
        "        super().__init__()\n",
        "        base = models.resnet101(weights=None)\n",
        "        sd = torch.load(\"/content/drive/MyDrive/resnet101-63fe2227.pth\", map_location=DEVICE)\n",
        "        base.load_state_dict(sd)\n",
        "        self.backbone = nn.Sequential(*list(base.children())[:-1])\n",
        "        self.view_indices = view_indices\n",
        "        dim = 2048 * len(view_indices)\n",
        "        self.fc = nn.Linear(dim, 1)\n",
        "    def forward(self, img1, img2, img3):\n",
        "        imgs = [img1, img2, img3]\n",
        "        feats = []\n",
        "        for i in self.view_indices:\n",
        "            x = self.backbone(imgs[i]).flatten(1)\n",
        "            feats.append(x)\n",
        "        fused = torch.cat(feats, dim=1)\n",
        "        return self.fc(fused)\n",
        "\n",
        "def compute_metrics(gt, pred):\n",
        "    gt, pred = np.asarray(gt), np.asarray(pred)\n",
        "    err = pred - gt\n",
        "    return {\n",
        "        \"r2\":          r2_score(gt,pred),\n",
        "        \"mae\":         mean_absolute_error(gt,pred),\n",
        "        \"tol_rate\":    np.mean(np.abs(err)<=1.0),\n",
        "        \"mean_bias\":   err.mean(),\n",
        "        \"error_std\":   err.std(),\n",
        "        \"ks\":          ks_2samp(gt,pred)[0],\n",
        "        \"wasserstein\": wasserstein_distance(gt,pred),\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    sample_json = \"/content/drive/MyDrive/sample_list.json\"\n",
        "    with open(sample_json) as f:\n",
        "        samples = json.load(f)\n",
        "    train = [s for s in samples if s[\"split\"]==\"Training\"]\n",
        "    val   = [s for s in samples if s[\"split\"]==\"Validation\"]\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        LetterboxResize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ])\n",
        "\n",
        "    train_ds = MultiViewBMIDataset3(train, transform=transform)\n",
        "    val_ds   = MultiViewBMIDataset3(val,   transform=transform)\n",
        "    train_loader = DataLoader(train_ds, batch_size=8, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "    val_loader   = DataLoader(val_ds,   batch_size=8, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "    experiments = [\n",
        "        (\"Single [0]\", [0]),\n",
        "        (\"Single [1]\", [1]),\n",
        "        (\"Single [2]\", [2]),\n",
        "        (\"Dual [0,1]\", [0,1]),\n",
        "        (\"Dual [0,2]\", [0,2]),\n",
        "        (\"Dual [1,2]\", [1,2]),\n",
        "        (\"Triple [0,1,2]\", [0,1,2]),\n",
        "    ]\n",
        "\n",
        "    EPOCHS = 20\n",
        "    LR = 1e-4\n",
        "    NUM_RUNS = 4\n",
        "\n",
        "    for name, views in experiments:\n",
        "        print(f\"\\n=== Experiment: {name} ===\")\n",
        "        summary = {k: [] for k in [\"r2\",\"mae\",\"tol_rate\",\"mean_bias\",\"error_std\",\"ks\",\"wasserstein\"]}\n",
        "        bucket_maes = {0:[],1:[],2:[]}\n",
        "\n",
        "        for run in range(1, NUM_RUNS+1):\n",
        "            model = FusedMultiViewBMIModel3(views).to(DEVICE)\n",
        "            opt   = optim.Adam(model.parameters(), lr=LR)\n",
        "            mse   = nn.MSELoss()\n",
        "            # train\n",
        "            for _ in range(EPOCHS):\n",
        "                model.train()\n",
        "                for i1,i2,i3,bmi in train_loader:\n",
        "                    i1,i2,i3,bmi = [x.to(DEVICE) for x in (i1,i2,i3,bmi)]\n",
        "                    opt.zero_grad()\n",
        "                    out = model(i1,i2,i3)\n",
        "                    loss = mse(out, bmi.unsqueeze(1))\n",
        "                    loss.backward()\n",
        "                    opt.step()\n",
        "            # eval\n",
        "            model.eval()\n",
        "            preds, gts = [],[]\n",
        "            with torch.no_grad():\n",
        "                for i1,i2,i3,bmi in val_loader:\n",
        "                    i1,i2,i3 = [x.to(DEVICE) for x in (i1,i2,i3)]\n",
        "                    out = model(i1,i2,i3)\n",
        "                    preds += out.cpu().flatten().tolist()\n",
        "                    gts   += bmi.flatten().tolist()\n",
        "            m = compute_metrics(gts, preds)\n",
        "            for k,v in m.items(): summary[k].append(v)\n",
        "            # bucket MAE\n",
        "            errs = np.abs(np.array(preds)-np.array(gts))\n",
        "            classes = np.array([get_bmi_class(x) for x in gts])\n",
        "            for b in (0,1,2):\n",
        "                sel = errs[classes==b]\n",
        "                bucket_maes[b].append(sel.mean() if sel.size>0 else np.nan)\n",
        "            print(f\" Run {run}/{NUM_RUNS} — \" +\n",
        "                  \", \".join(f\"{k}={m[k]:.4f}\" for k in summary.keys()))\n",
        "\n",
        "        # print summary\n",
        "        print(f\"\\n--- Summary for {name} ---\")\n",
        "        for k, vals in summary.items():\n",
        "            a = np.array(vals)\n",
        "            print(f\"  {k.upper():10s}: {a.mean():.4f} ± {a.std():.4f}\")\n",
        "        # print & plot bucket MAE\n",
        "        names = [\"Under\",\"Normal\",\"Over\"]\n",
        "        mean_mae = [np.nanmean(bucket_maes[b]) for b in (0,1,2)]\n",
        "        std_mae  = [np.nanstd(bucket_maes[b])  for b in (0,1,2)]\n",
        "        for b,nm in enumerate(names):\n",
        "            print(f\"  Bucket {nm:6s} MAE: {mean_mae[b]:.4f} ± {std_mae[b]:.4f}\")\n",
        "        plt.figure()\n",
        "        plt.bar(names, mean_mae, yerr=std_mae, capsize=5)\n",
        "        plt.ylabel(\"MAE\"); plt.title(f\"Bucket MAE: {name}\")\n",
        "        plt.show()\n"
      ]
    }
  ]
}