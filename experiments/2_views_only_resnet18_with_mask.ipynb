{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sg_WB762DpGv"
   },
   "outputs": [],
   "source": [
    "!pip install 'git+https://github.com/facebookresearch/detectron2.git'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIzZVtJZDiz7"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# two_view_human_ref_res18_letterbox_with_buckets.py\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from typing import List, Dict\n",
    "from PIL import Image, ImageOps\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from scipy.stats import ks_2samp, wasserstein_distance\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from transformers import pipeline\n",
    "\n",
    "# CONFIGURATION\n",
    "BASE_DIR       = \"/content/drive/MyDrive\"\n",
    "SAMPLE_JSON    = os.path.join(BASE_DIR, \"sample_list.json\")\n",
    "RESNET18_PATH  = os.path.join(BASE_DIR, \"resnet18-5c106cde.pth\")\n",
    "HUMAN_NPZ_PATH = os.path.join(BASE_DIR, \"human_mask_cache_224.npz\")\n",
    "REF_NPZ_PATH   = os.path.join(BASE_DIR, \"ref_mask_cache_224.npz\")\n",
    "REF_LABELS     = [\"a white ball\", \"a dark paper\"]\n",
    "DEVICE         = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "OUT_W, OUT_H   = 224, 224\n",
    "\n",
    "# LETTERBOX MASK\n",
    "def letterbox_mask(mask: np.ndarray, new_size=(OUT_W, OUT_H)) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Resize binary mask to new_size via letterbox padding.\n",
    "    \"\"\"\n",
    "    h, w = mask.shape\n",
    "    nw, nh = new_size\n",
    "    scale = min(nw / w, nh / h)\n",
    "    rw, rh = int(w * scale), int(h * scale)\n",
    "    resized = cv2.resize(mask, (rw, rh), interpolation=cv2.INTER_NEAREST)\n",
    "    top = (nh - rh) // 2\n",
    "    left = (nw - rw) // 2\n",
    "    out = np.zeros((nh, nw), dtype=mask.dtype)\n",
    "    out[top:top+rh, left:left+rw] = resized\n",
    "    return out\n",
    "\n",
    "# BUILD MASK CACHES\n",
    "def build_mask_caches(samples: List[Dict],\n",
    "                      human_pred: DefaultPredictor,\n",
    "                      ref_det,\n",
    "                      ref_labels: List[str]) -> None:\n",
    "    \"\"\"\n",
    "    Generate and save letterboxed human and reference masks for the first two views.\n",
    "    \"\"\"\n",
    "    if os.path.exists(HUMAN_NPZ_PATH) and os.path.exists(REF_NPZ_PATH):\n",
    "        return\n",
    "    human_cache, ref_cache = {}, {}\n",
    "    for s in tqdm(samples, desc=\"Building mask caches\"):\n",
    "        for path in s[\"img_paths\"][:2]:\n",
    "            if path in human_cache or not os.path.exists(path):\n",
    "                continue\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            img = ImageOps.exif_transpose(img)\n",
    "            arr = np.array(img); H, W = arr.shape[:2]\n",
    "            inst = human_pred(cv2.cvtColor(arr, cv2.COLOR_RGB2BGR))[\"instances\"]\n",
    "            hm = np.zeros((H, W), dtype=np.uint8)\n",
    "            if len(inst):\n",
    "                cls = inst.pred_classes.cpu().numpy()\n",
    "                ids = np.where(cls == 0)[0]\n",
    "                if len(ids):\n",
    "                    idx = ids[inst.scores.cpu().numpy()[ids].argmax()]\n",
    "                    if inst.has(\"pred_masks\"):\n",
    "                        hm = inst.pred_masks[idx].cpu().numpy().astype(np.uint8)\n",
    "                    else:\n",
    "                        y0,x0,y1,x1 = inst.pred_boxes[idx].tensor.cpu().numpy()[0]\n",
    "                        hm[int(y0):int(y1), int(x0):int(x1)] = 1\n",
    "            human_cache[path] = letterbox_mask(hm)\n",
    "            dets = ref_det(img, candidate_labels=ref_labels, threshold=0.7)\n",
    "            det_map = {d[\"label\"].lower(): d for d in dets}\n",
    "            for lbl in ref_labels:\n",
    "                key = f\"{path}|{lbl}\"\n",
    "                rm = np.zeros((H, W), dtype=np.uint8)\n",
    "                d  = det_map.get(lbl)\n",
    "                if d:\n",
    "                    x0,y0 = int(d[\"box\"][\"xmin\"]), int(d[\"box\"][\"ymin\"])\n",
    "                    x1,y1 = int(d[\"box\"][\"xmax\"]), int(d[\"box\"][\"ymax\"])\n",
    "                    rm[y0:y1, x0:x1] = 1\n",
    "                ref_cache[key] = letterbox_mask(rm)\n",
    "    np.savez_compressed(HUMAN_NPZ_PATH, **human_cache)\n",
    "    np.savez_compressed(REF_NPZ_PATH,   **ref_cache)\n",
    "\n",
    "# DATASET\n",
    "class MaskOnlyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset returning two human masks + two ref masks + BMI.\n",
    "    \"\"\"\n",
    "    def __init__(self, samples: List[Dict], ref_labels: List[str]):\n",
    "        self.samples    = samples\n",
    "        self.ref_labels = ref_labels\n",
    "        self.h_masks    = dict(np.load(HUMAN_NPZ_PATH, allow_pickle=True))\n",
    "        self.r_masks    = dict(np.load(REF_NPZ_PATH,   allow_pickle=True))\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        s = self.samples[idx]\n",
    "        p1, p2 = s[\"img_paths\"][:2]\n",
    "        hm1 = torch.from_numpy(self.h_masks[p1]).unsqueeze(0).float()\n",
    "        hm2 = torch.from_numpy(self.h_masks[p2]).unsqueeze(0).float()\n",
    "        rm1 = np.stack([self.r_masks[f\"{p1}|{lbl}\"] for lbl in self.ref_labels], 0)\n",
    "        rm2 = np.stack([self.r_masks[f\"{p2}|{lbl}\"] for lbl in self.ref_labels], 0)\n",
    "        rm1, rm2 = torch.from_numpy(rm1).float(), torch.from_numpy(rm2).float()\n",
    "        bmi = torch.tensor(float(s[\"bmi\"]), dtype=torch.float32).unsqueeze(0)\n",
    "        return hm1, hm2, rm1, rm2, bmi\n",
    "\n",
    "# MODEL\n",
    "class TwoViewHumanRefRes18(nn.Module):\n",
    "    \"\"\"\n",
    "    Two-view BMI regression + classification:\n",
    "      - Human-mask branch: ResNet-18\n",
    "      - Reference-mask branch: ResNet-18\n",
    "    \"\"\"\n",
    "    def __init__(self, num_ref: int):\n",
    "        super().__init__()\n",
    "        h18 = models.resnet18(weights=None)\n",
    "        sd = torch.load(RESNET18_PATH, map_location=\"cpu\", weights_only=False)\n",
    "        h18.load_state_dict(sd, strict=False)\n",
    "        w0 = h18.conv1.weight.data\n",
    "        h18.conv1 = nn.Conv2d(1,64,7,2,3,bias=False)\n",
    "        h18.conv1.weight.data = w0.mean(dim=1,keepdim=True)\n",
    "        self.h_backbone = nn.Sequential(*list(h18.children())[:-1])\n",
    "        r18 = models.resnet18(weights=None)\n",
    "        r18.load_state_dict(sd, strict=False)\n",
    "        w1 = r18.conv1.weight.data.mean(dim=1,keepdim=True)\n",
    "        r18.conv1 = nn.Conv2d(num_ref,64,7,2,3,bias=False)\n",
    "        r18.conv1.weight.data = w1.repeat(1,num_ref,1,1)\n",
    "        self.r_backbone = nn.Sequential(*list(r18.children())[:-1])\n",
    "        in_dim = (512 + 512) * 2\n",
    "        self.fc_reg = nn.Linear(in_dim, 1)\n",
    "        self.fc_cls = nn.Linear(in_dim, 3)\n",
    "    def forward(self, hm1, hm2, rm1, rm2):\n",
    "        def f(b,x): return b(x).flatten(1)\n",
    "        h1, h2 = f(self.h_backbone, hm1), f(self.h_backbone, hm2)\n",
    "        r1, r2 = f(self.r_backbone, rm1), f(self.r_backbone, rm2)\n",
    "        v1, v2 = torch.cat([h1,r1],1), torch.cat([h2,r2],1)\n",
    "        fused = torch.cat([v1,v2],1)\n",
    "        return self.fc_reg(fused), self.fc_cls(fused)\n",
    "\n",
    "# UTILITIES\n",
    "def get_bmi_class_new(bmi: float) -> int:\n",
    "    if bmi < 17.28: return 0\n",
    "    if bmi < 25.57: return 1\n",
    "    return 2\n",
    "\n",
    "def compute_metrics(gt, pred):\n",
    "    gt, pred = np.asarray(gt), np.asarray(pred)\n",
    "    err = pred - gt\n",
    "    ks, _ = ks_2samp(gt, pred)\n",
    "    return {\n",
    "        \"r2\":          r2_score(gt, pred),\n",
    "        \"mae\":         mean_absolute_error(gt, pred),\n",
    "        \"tol_rate\":    np.mean(np.abs(err) <= 1.0),\n",
    "        \"mean_bias\":   err.mean(),\n",
    "        \"error_std\":   err.std(),\n",
    "        \"ks\":          ks,\n",
    "        \"wasserstein\": wasserstein_distance(gt, pred),\n",
    "    }\n",
    "\n",
    "# MAIN\n",
    "if __name__==\"__main__\":\n",
    "    with open(SAMPLE_JSON) as f: samples = json.load(f)\n",
    "    BUILD_CACHE = False\n",
    "    if BUILD_CACHE:\n",
    "        cfg = get_cfg()\n",
    "        cfg.merge_from_file(model_zoo.get_config_file(\n",
    "            \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "        cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "        cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n",
    "            \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "        human_pred = DefaultPredictor(cfg)\n",
    "        ref_det    = pipeline(\"zero-shot-object-detection\",\n",
    "                              model=\"IDEA-Research/grounding-dino-tiny\",\n",
    "                              device=0 if torch.cuda.is_available() else -1)\n",
    "        build_mask_caches(samples, human_pred, ref_det, REF_LABELS)\n",
    "        exit(0)\n",
    "\n",
    "    train = [s for s in samples if s[\"split\"]==\"Training\"]\n",
    "    val   = [s for s in samples if s[\"split\"]==\"Validation\"]\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        MaskOnlyDataset(train, REF_LABELS),\n",
    "        batch_size=8, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "    val_loader   = DataLoader(\n",
    "        MaskOnlyDataset(val,   REF_LABELS),\n",
    "        batch_size=8, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    CHECKPOINTS = [20,25,30,35]\n",
    "    NUM_RUNS    = 3\n",
    "    EPOCHS      = 35\n",
    "\n",
    "    overall_results = {ep: {k:[] for k in compute_metrics([0],[0])} for ep in CHECKPOINTS}\n",
    "    bucket_results  = {ep: {0:[],1:[],2:[]} for ep in CHECKPOINTS}\n",
    "\n",
    "    for run in range(1,NUM_RUNS+1):\n",
    "        print(f\"\\n===== RUN {run} =====\")\n",
    "        model     = TwoViewHumanRefRes18(len(REF_LABELS)).to(DEVICE)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "        mse_loss  = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(1,EPOCHS+1):\n",
    "            model.train()\n",
    "            for hm1,hm2,rm1,rm2,bmi in train_loader:\n",
    "                hm1,hm2,rm1,rm2,bmi = [x.to(DEVICE) for x in (hm1,hm2,rm1,rm2,bmi)]\n",
    "                labels = torch.tensor(\n",
    "                    [get_bmi_class_new(b.item()) for b in bmi.flatten()],\n",
    "                    dtype=torch.long, device=DEVICE\n",
    "                )\n",
    "                optimizer.zero_grad()\n",
    "                out_reg, out_cls = model(hm1,hm2,rm1,rm2)\n",
    "                loss = mse_loss(out_reg, bmi)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if epoch in CHECKPOINTS:\n",
    "                model.eval()\n",
    "                all_preds, all_gts, all_buckets = [], [], []\n",
    "                with torch.no_grad():\n",
    "                    for hm1,hm2,rm1,rm2,bmi in val_loader:\n",
    "                        hm1,hm2,rm1,rm2 = [x.to(DEVICE) for x in (hm1,hm2,rm1,rm2)]\n",
    "                        preds, _ = model(hm1,hm2,rm1,rm2)\n",
    "                        p = preds.cpu().flatten().tolist()\n",
    "                        g = bmi.flatten().tolist()\n",
    "                        b = [get_bmi_class_new(float(x)) for x in g]\n",
    "                        all_preds   += p\n",
    "                        all_gts     += g\n",
    "                        all_buckets += b\n",
    "\n",
    "                metrics = compute_metrics(all_gts, all_preds)\n",
    "                print(f\"\\n--- Epoch {epoch} ---\")\n",
    "                for k,v in metrics.items(): print(f\"{k}: {v:.4f}\", end=\"  \")\n",
    "                print()\n",
    "                for k,v in metrics.items(): overall_results[epoch][k].append(v)\n",
    "\n",
    "                errors = np.abs(np.array(all_preds) - np.array(all_gts))\n",
    "                arr_buckets = np.array(all_buckets)\n",
    "                names = [\"Underweight\",\"Normal\",\"Overweight\"]\n",
    "                bucket_mae = [errors[arr_buckets==b].mean() if (arr_buckets==b).sum()>0 else np.nan\n",
    "                              for b in (0,1,2)]\n",
    "                for i,b in enumerate((0,1,2)):\n",
    "                    bucket_results[epoch][b].append(bucket_mae[i])\n",
    "\n",
    "                plt.figure(figsize=(6,4))\n",
    "                plt.bar(names, bucket_mae)\n",
    "                plt.ylabel(\"MAE\"); plt.title(f\"MAE by BMI Bucket @ epoch {epoch}\")\n",
    "                plt.show()\n",
    "\n",
    "                data = [errors[arr_buckets==b] for b in (0,1,2)]\n",
    "                plt.figure(figsize=(6,4))\n",
    "                plt.boxplot(data, labels=names)\n",
    "                plt.ylabel(\"Absolute Error\"); plt.title(f\"Error Distribution by Bucket @ epoch {epoch}\")\n",
    "                plt.show()\n",
    "\n",
    "                plt.figure(figsize=(7,6))\n",
    "                for b,c in zip((0,1,2),(\"C0\",\"C1\",\"C2\")):\n",
    "                    mask = arr_buckets==b\n",
    "                    plt.scatter(np.array(all_gts)[mask], np.array(all_preds)[mask],\n",
    "                                alpha=0.6, label=names[b], c=c)\n",
    "                mval, Mval = min(all_gts+all_preds), max(all_gts+all_preds)\n",
    "                plt.plot([mval,Mval],[mval,Mval],\"k--\")\n",
    "                plt.xlabel(\"True BMI\"); plt.ylabel(\"Predicted BMI\")\n",
    "                plt.legend(); plt.title(f\"Pred vs True @ epoch {epoch}\")\n",
    "                plt.show()\n",
    "\n",
    "    print(\"\\n===== SUMMARY =====\")\n",
    "    for ep in CHECKPOINTS:\n",
    "        print(f\"\\nCheckpoint {ep}:\")\n",
    "        for k, vals in overall_results[ep].items():\n",
    "            arr = np.array(vals)\n",
    "            print(f\"  {k.upper():12s} {arr.mean():.4f} ± {arr.std():.4f}\")\n",
    "        print(\"  BUCKET MAE:\")\n",
    "        for b,name in zip((0,1,2),names):\n",
    "            arr = np.array(bucket_results[ep][b])\n",
    "            print(f\"    {name:12s}: {arr.mean():.4f} ± {arr.std():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
