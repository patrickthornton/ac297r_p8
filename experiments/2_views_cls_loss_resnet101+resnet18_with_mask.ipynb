{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGcszyfS0NPO"
   },
   "outputs": [],
   "source": [
    "!pip install 'git+https://github.com/facebookresearch/detectron2.git'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z5aGV7Au0oj_"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# two_view_bmi_res101_res18_letterbox_no_proj_with_cls_and_buckets.py\n",
    "# Based on original script: adds classification weight factor loop, classification loss,\n",
    "# computes bucketed MAE, classification accuracy, and visualizations.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "import os, json, time, cv2, numpy as np, torch\n",
    "from typing import List, Dict\n",
    "from PIL import Image, ImageOps\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from scipy.stats import ks_2samp, wasserstein_distance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from transformers import pipeline\n",
    "\n",
    "# ----------------------------- CONFIG -------------------------------\n",
    "BASE_DIR         = \"/content/drive/MyDrive\"\n",
    "SAMPLE_JSON_PATH = os.path.join(BASE_DIR, \"sample_list.json\")\n",
    "RESNET101_PATH   = os.path.join(BASE_DIR, \"resnet101-63fe2227.pth\")\n",
    "RESNET18_PATH    = os.path.join(BASE_DIR, \"resnet18-5c106cde.pth\")\n",
    "HUMAN_NPZ_PATH   = os.path.join(BASE_DIR, \"human_mask_cache_224.npz\")\n",
    "REF_NPZ_PATH     = os.path.join(BASE_DIR, \"ref_mask_cache_224.npz\")\n",
    "REF_LABELS       = [\"a dark paper\", \"a white ball\"]\n",
    "DEVICE           = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "OUT_W, OUT_H     = 224, 224\n",
    "\n",
    "def letterbox_mask(mask: np.ndarray, new_size=(OUT_W, OUT_H)) -> np.ndarray:\n",
    "    h, w = mask.shape\n",
    "    nw, nh = new_size\n",
    "    scale = min(nw / w, nh / h)\n",
    "    rw, rh = int(w * scale), int(h * scale)\n",
    "    resized = cv2.resize(mask, (rw, rh), interpolation=cv2.INTER_NEAREST)\n",
    "    top = (nh - rh) // 2\n",
    "    left = (nw - rw) // 2\n",
    "    out = np.zeros((nh, nw), dtype=mask.dtype)\n",
    "    out[top:top+rh, left:left+rw] = resized\n",
    "    return out\n",
    "\n",
    "def build_mask_caches(samples: List[Dict],\n",
    "                      person_pred: DefaultPredictor,\n",
    "                      ref_det,\n",
    "                      ref_labels: List[str]) -> None:\n",
    "    if os.path.exists(HUMAN_NPZ_PATH) and os.path.exists(REF_NPZ_PATH):\n",
    "        return\n",
    "    human_cache, ref_cache = {}, {}\n",
    "    for s in tqdm(samples, desc=\"Building mask caches\"):\n",
    "        for p in s[\"img_paths\"][:2]:\n",
    "            if p in human_cache or not os.path.exists(p):\n",
    "                continue\n",
    "            pil = Image.open(p).convert(\"RGB\")\n",
    "            pil = ImageOps.exif_transpose(pil)\n",
    "            arr = np.array(pil); H, W = arr.shape[:2]\n",
    "            inst = person_pred(cv2.cvtColor(arr, cv2.COLOR_RGB2BGR))[\"instances\"]\n",
    "            hm = np.zeros((H, W), dtype=np.uint8)\n",
    "            if len(inst):\n",
    "                cls = inst.pred_classes.cpu().numpy()\n",
    "                ids = np.where(cls == 0)[0]\n",
    "                if len(ids):\n",
    "                    idx = ids[inst.scores.cpu().numpy()[ids].argmax()]\n",
    "                    if inst.has(\"pred_masks\"):\n",
    "                        hm = inst.pred_masks[idx].cpu().numpy().astype(np.uint8)\n",
    "                    else:\n",
    "                        y0,x0,y1,x1 = inst.pred_boxes[idx].tensor.cpu().numpy()[0]\n",
    "                        hm[int(y0):int(y1), int(x0):int(x1)] = 1\n",
    "            human_cache[p] = letterbox_mask(hm)\n",
    "            dets = ref_det(pil, candidate_labels=ref_labels, threshold=0.7)\n",
    "            det_map = {d[\"label\"].lower(): d for d in dets}\n",
    "            for lbl in ref_labels:\n",
    "                key = f\"{p}|{lbl}\"\n",
    "                rm = np.zeros((H, W), dtype=np.uint8)\n",
    "                d = det_map.get(lbl)\n",
    "                if d:\n",
    "                    x0,y0 = int(d[\"box\"][\"xmin\"]), int(d[\"box\"][\"ymin\"])\n",
    "                    x1,y1 = int(d[\"box\"][\"xmax\"]), int(d[\"box\"][\"ymax\"])\n",
    "                    rm[y0:y1, x0:x1] = 1\n",
    "                ref_cache[key] = letterbox_mask(rm)\n",
    "    np.savez_compressed(HUMAN_NPZ_PATH, **human_cache)\n",
    "    np.savez_compressed(REF_NPZ_PATH,   **ref_cache)\n",
    "\n",
    "class TwoViewMaskDataset(Dataset):\n",
    "    def __init__(self, samples: List[Dict], resize, tf, ref_labels: List[str]):\n",
    "        self.samples, self.resize, self.tf, self.ref_labels = samples, resize, tf, ref_labels\n",
    "        self.h_masks = dict(np.load(HUMAN_NPZ_PATH, allow_pickle=True))\n",
    "        self.r_masks = dict(np.load(REF_NPZ_PATH,   allow_pickle=True))\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        s = self.samples[idx]\n",
    "        p1, p2 = s[\"img_paths\"][:2]\n",
    "        img1 = Image.open(p1).convert(\"RGB\"); img2 = Image.open(p2).convert(\"RGB\")\n",
    "        rgb1, rgb2 = self.tf(self.resize(img1)), self.tf(self.resize(img2))\n",
    "        m1 = torch.from_numpy(self.h_masks[p1]).unsqueeze(0).float()\n",
    "        m2 = torch.from_numpy(self.h_masks[p2]).unsqueeze(0).float()\n",
    "        rm1 = np.stack([self.r_masks[f\"{p1}|{lbl}\"] for lbl in self.ref_labels], 0)\n",
    "        rm2 = np.stack([self.r_masks[f\"{p2}|{lbl}\"] for lbl in self.ref_labels], 0)\n",
    "        rm1, rm2 = torch.from_numpy(rm1).float(), torch.from_numpy(rm2).float()\n",
    "        bmi = torch.tensor(float(s[\"bmi\"]), dtype=torch.float32).unsqueeze(0)\n",
    "        return rgb1, rgb2, m1, m2, rm1, rm2, bmi\n",
    "\n",
    "class MultiBranchNoProj(nn.Module):\n",
    "    def __init__(self, num_ref: int = 2, num_classes: int = 3):\n",
    "        super().__init__()\n",
    "        r101 = models.resnet101(weights=None)\n",
    "        sd = torch.load(RESNET101_PATH, map_location=\"cpu\", weights_only=False)\n",
    "        r101.load_state_dict(sd, strict=False)\n",
    "        self.rgb_backbone = nn.Sequential(*list(r101.children())[:-1])\n",
    "        h18 = models.resnet18(weights=None)\n",
    "        sd = torch.load(RESNET18_PATH, map_location=\"cpu\", weights_only=False)\n",
    "        h18.load_state_dict(sd, strict=False)\n",
    "        w0 = h18.conv1.weight.data\n",
    "        h18.conv1 = nn.Conv2d(1,64,7,2,3,bias=False)\n",
    "        h18.conv1.weight.data = w0.mean(dim=1,keepdim=True)\n",
    "        self.h_backbone = nn.Sequential(*list(h18.children())[:-1])\n",
    "        r18 = models.resnet18(weights=None)\n",
    "        sd = torch.load(RESNET18_PATH, map_location=\"cpu\", weights_only=False)\n",
    "        r18.load_state_dict(sd, strict=False)\n",
    "        w1 = r18.conv1.weight.data.mean(dim=1,keepdim=True)\n",
    "        r18.conv1 = nn.Conv2d(num_ref,64,7,2,3,bias=False)\n",
    "        r18.conv1.weight.data = w1.repeat(1,num_ref,1,1)\n",
    "        self.r_backbone = nn.Sequential(*list(r18.children())[:-1])\n",
    "        in_dim = (2048 + 512 + 512) * 2\n",
    "        self.fc_reg = nn.Linear(in_dim, 1)\n",
    "        self.fc_cls = nn.Linear(in_dim, num_classes)\n",
    "    def forward(self, rgb1,rgb2,hm1,hm2,rm1,rm2):\n",
    "        def feat(b,x): return b(x).flatten(1)\n",
    "        r1,r2 = feat(self.rgb_backbone,rgb1), feat(self.rgb_backbone,rgb2)\n",
    "        h1,h2 = feat(self.h_backbone,  hm1),   feat(self.h_backbone,  hm2)\n",
    "        f1,f2 = feat(self.r_backbone,   rm1),   feat(self.r_backbone,   rm2)\n",
    "        v1 = torch.cat([r1,h1,f1],1); v2 = torch.cat([r2,h2,f2],1)\n",
    "        x = torch.cat([v1,v2],1)\n",
    "        return self.fc_reg(x), self.fc_cls(x)\n",
    "\n",
    "def compute_metrics(gt, pred):\n",
    "    gt,pred = np.asarray(gt), np.asarray(pred)\n",
    "    err = pred - gt\n",
    "    ks,_= ks_2samp(gt,pred)\n",
    "    return {\n",
    "        \"r2\":          r2_score(gt,pred),\n",
    "        \"mae\":         mean_absolute_error(gt,pred),\n",
    "        \"tol_rate\":    np.mean(np.abs(err)<=1.0),\n",
    "        \"mean_bias\":   err.mean(),\n",
    "        \"error_std\":   err.std(),\n",
    "        \"ks\":          ks,\n",
    "        \"wasserstein\": wasserstein_distance(gt,pred),\n",
    "    }\n",
    "\n",
    "def get_bmi_class_new(bmi: float) -> int:\n",
    "    if bmi<17.28: return 0\n",
    "    if bmi<25.57: return 1\n",
    "    return 2\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    with open(SAMPLE_JSON_PATH) as f:\n",
    "        samples = json.load(f)\n",
    "\n",
    "    BUILD_CACHE = False\n",
    "    if BUILD_CACHE:\n",
    "        cfg = get_cfg()\n",
    "        cfg.merge_from_file(model_zoo.get_config_file(\n",
    "            \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "        cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "        cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n",
    "            \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "        human_pred = DefaultPredictor(cfg)\n",
    "        ref_det    = pipeline(\"zero-shot-object-detection\",\n",
    "                              model=\"IDEA-Research/grounding-dino-tiny\",\n",
    "                              device=0 if torch.cuda.is_available() else -1)\n",
    "        build_mask_caches(samples, human_pred, ref_det, REF_LABELS)\n",
    "        exit(0)\n",
    "\n",
    "    train = [s for s in samples if s[\"split\"]==\"Training\"]\n",
    "    val   = [s for s in samples if s[\"split\"]==\"Validation\"]\n",
    "\n",
    "    resize = transforms.Resize((OUT_H, OUT_W))\n",
    "    tf     = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])\n",
    "    train_loader = DataLoader(\n",
    "        TwoViewMaskDataset(train, resize, tf, REF_LABELS),\n",
    "        batch_size=8, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "    val_loader   = DataLoader(\n",
    "        TwoViewMaskDataset(val,   resize, tf, REF_LABELS),\n",
    "        batch_size=8, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    CHECKPOINTS    = [20,25,30,35]\n",
    "    NUM_RUNS       = 3\n",
    "    EPOCHS         = 35\n",
    "    weight_factors = [1,2,3,5,8]\n",
    "\n",
    "    for wf in weight_factors:\n",
    "        print(f\"\\n=== CLS weight factor = {wf} ===\")\n",
    "        metric_keys = list(compute_metrics([0],[0]).keys()) + [\"cls_acc\",\n",
    "                         \"bucket_0_mae\",\"bucket_1_mae\",\"bucket_2_mae\"]\n",
    "        results = {ep:{k:[] for k in metric_keys} for ep in CHECKPOINTS}\n",
    "\n",
    "        for run in range(1,NUM_RUNS+1):\n",
    "            print(f\"\\n--- Run {run} ---\")\n",
    "            model = MultiBranchNoProj(num_ref=len(REF_LABELS), num_classes=3).to(DEVICE)\n",
    "            optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "            mse = nn.MSELoss()\n",
    "            cw  = torch.tensor([wf,1.0,wf], device=DEVICE)\n",
    "            ce  = nn.CrossEntropyLoss(weight=cw)\n",
    "\n",
    "            for ep in range(1,EPOCHS+1):\n",
    "                model.train()\n",
    "                for rgb1,rgb2,hm1,hm2,rm1,rm2,bmi in train_loader:\n",
    "                    rgb1,rgb2,hm1,hm2,rm1,rm2,bmi = [\n",
    "                        x.to(DEVICE) for x in (rgb1,rgb2,hm1,hm2,rm1,rm2,bmi)\n",
    "                    ]\n",
    "                    labels = torch.tensor([get_bmi_class_new(b.item()) for b in bmi.flatten()],\n",
    "                                          device=DEVICE, dtype=torch.long)\n",
    "                    optimizer.zero_grad()\n",
    "                    out_reg, out_cls = model(rgb1,rgb2,hm1,hm2,rm1,rm2)\n",
    "                    loss = mse(out_reg, bmi) + ce(out_cls, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                if ep in CHECKPOINTS:\n",
    "                    model.eval()\n",
    "                    all_p, all_t, all_c = [], [], []\n",
    "                    with torch.no_grad():\n",
    "                        for rgb1,rgb2,hm1,hm2,rm1,rm2,bmi in val_loader:\n",
    "                            rgb1,rgb2,hm1,hm2,rm1,rm2 = [\n",
    "                                x.to(DEVICE) for x in (rgb1,rgb2,hm1,hm2,rm1,rm2)\n",
    "                            ]\n",
    "                            p_reg,p_cls = model(rgb1,rgb2,hm1,hm2,rm1,rm2)\n",
    "                            preds = p_reg.cpu().flatten().tolist()\n",
    "                            truths= bmi.flatten().tolist()\n",
    "                            cp = torch.argmax(p_cls,dim=1).cpu().tolist()\n",
    "                            all_p += preds; all_t += truths; all_c += cp\n",
    "\n",
    "                    m   = compute_metrics(all_t, all_p)\n",
    "                    acc = np.mean(np.array(all_c)==np.array([get_bmi_class_new(x) for x in all_t]))\n",
    "                    print(f\"Epoch {ep}:\", \", \".join(f\"{k}={v:.4f}\" for k,v in m.items()),\n",
    "                          f\"cls_acc={acc*100:.2f}%\")\n",
    "                    for k,v in m.items(): results[ep][k].append(v)\n",
    "                    results[ep][\"cls_acc\"].append(acc)\n",
    "\n",
    "                    errors = np.abs(np.array(all_p)-np.array(all_t))\n",
    "                    buckets = np.array([get_bmi_class_new(x) for x in all_t])\n",
    "                    bucket_mae = [(errors[buckets==b].mean() if (buckets==b).sum()>0 else np.nan)\n",
    "                                  for b in (0,1,2)]\n",
    "                    results[ep][\"bucket_0_mae\"].append(bucket_mae[0])\n",
    "                    results[ep][\"bucket_1_mae\"].append(bucket_mae[1])\n",
    "                    results[ep][\"bucket_2_mae\"].append(bucket_mae[2])\n",
    "\n",
    "                    # visualize bucket MAE\n",
    "                    names = [\"Underweight\",\"Normal\",\"Overweight\"]\n",
    "                    plt.figure(figsize=(6,4))\n",
    "                    plt.bar(names, bucket_mae)\n",
    "                    plt.ylabel(\"MAE\")\n",
    "                    plt.title(f\"Bucket MAE @ wf={wf}, ep={ep}\")\n",
    "                    plt.show()\n",
    "\n",
    "                    # boxplot of errors\n",
    "                    data = [errors[buckets==b] for b in (0,1,2)]\n",
    "                    plt.figure(figsize=(6,4))\n",
    "                    plt.boxplot(data, labels=names)\n",
    "                    plt.ylabel(\"Absolute Error\")\n",
    "                    plt.title(f\"Error Dist by Bucket @ wf={wf}, ep={ep}\")\n",
    "                    plt.show()\n",
    "\n",
    "                    # scatter by bucket\n",
    "                    plt.figure(figsize=(7,6))\n",
    "                    for b,c in zip((0,1,2),(\"C0\",\"C1\",\"C2\")):\n",
    "                        mask = buckets==b\n",
    "                        plt.scatter(np.array(all_t)[mask], np.array(all_p)[mask],\n",
    "                                    alpha=0.6, label=names[b], c=c)\n",
    "                    mval, Mval = min(all_t+all_p), max(all_t+all_p)\n",
    "                    plt.plot([mval,Mval],[mval,Mval],\"k--\")\n",
    "                    plt.xlabel(\"True BMI\"); plt.ylabel(\"Pred BMI\")\n",
    "                    plt.legend(); plt.title(f\"Pred vs True @ wf={wf}, ep={ep}\")\n",
    "                    plt.show()\n",
    "\n",
    "        print(f\"\\n--- Summary for wf={wf} ---\")\n",
    "        for ep in CHECKPOINTS:\n",
    "            print(f\"\\nCheckpoint {ep}:\")\n",
    "            for k,vals in results[ep].items():\n",
    "                arr = np.array(vals)\n",
    "                if k==\"cls_acc\":\n",
    "                    print(f\"  {k:12s} {arr.mean()*100:.2f}% ± {arr.std()*100:.2f}%\")\n",
    "                else:\n",
    "                    print(f\"  {k.upper():12s} {arr.mean():.4f} ± {arr.std():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
