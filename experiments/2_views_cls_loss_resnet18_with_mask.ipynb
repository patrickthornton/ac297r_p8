{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGcszyfS0NPO"
   },
   "outputs": [],
   "source": [
    "!pip install 'git+https://github.com/facebookresearch/detectron2.git'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z5aGV7Au0oj_"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# two_view_human_ref_res18_letterbox_with_cls_and_buckets.py\n",
    "# Extends two_view_human_ref_res18_letterbox.py:\n",
    "# adds classification loss weight loop, bucket‐MAE, cls_acc, visualizations, multi‐run and checkpoint summaries.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "import os, json, cv2, numpy as np, torch\n",
    "from typing import List, Dict\n",
    "from PIL import Image, ImageOps\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from scipy.stats import ks_2samp, wasserstein_distance\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from transformers import pipeline\n",
    "\n",
    "# CONFIGURATION\n",
    "BASE_DIR        = \"/content/drive/MyDrive\"\n",
    "SAMPLE_JSON     = os.path.join(BASE_DIR, \"sample_list.json\")\n",
    "RESNET18_PATH   = os.path.join(BASE_DIR, \"resnet18-5c106cde.pth\")\n",
    "HUMAN_NPZ_PATH  = os.path.join(BASE_DIR, \"human_mask_cache_224.npz\")\n",
    "REF_NPZ_PATH    = os.path.join(BASE_DIR, \"ref_mask_cache_224.npz\")\n",
    "REF_LABELS      = [\"a white ball\", \"a dark paper\"]\n",
    "DEVICE          = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "OUT_W, OUT_H    = 224, 224\n",
    "\n",
    "def letterbox_mask(mask: np.ndarray, new_size=(OUT_W, OUT_H)) -> np.ndarray:\n",
    "    h, w = mask.shape\n",
    "    nw, nh = new_size\n",
    "    scale = min(nw/w, nh/h)\n",
    "    rw, rh = int(w*scale), int(h*scale)\n",
    "    resized = cv2.resize(mask, (rw, rh), interpolation=cv2.INTER_NEAREST)\n",
    "    top, left = (nh-rh)//2, (nw-rw)//2\n",
    "    out = np.zeros((nh, nw), dtype=mask.dtype)\n",
    "    out[top:top+rh, left:left+rw] = resized\n",
    "    return out\n",
    "\n",
    "def build_mask_caches(samples: List[Dict], human_pred: DefaultPredictor, ref_det, ref_labels: List[str]):\n",
    "    if os.path.exists(HUMAN_NPZ_PATH) and os.path.exists(REF_NPZ_PATH):\n",
    "        return\n",
    "    human_cache, ref_cache = {}, {}\n",
    "    for s in tqdm(samples, desc=\"Building mask cache\"):\n",
    "        for p in s[\"img_paths\"][:2]:\n",
    "            if p in human_cache or not os.path.exists(p):\n",
    "                continue\n",
    "            img = Image.open(p).convert(\"RGB\")\n",
    "            img = ImageOps.exif_transpose(img)\n",
    "            arr = np.array(img); H, W = arr.shape[:2]\n",
    "            inst = human_pred(cv2.cvtColor(arr, cv2.COLOR_RGB2BGR))[\"instances\"]\n",
    "            hm = np.zeros((H, W), dtype=np.uint8)\n",
    "            if len(inst):\n",
    "                cls = inst.pred_classes.cpu().numpy()\n",
    "                ids = np.where(cls==0)[0]\n",
    "                if ids.size:\n",
    "                    i = ids[inst.scores[ids].argmax()]\n",
    "                    if inst.has(\"pred_masks\"):\n",
    "                        hm = inst.pred_masks[i].cpu().numpy().astype(np.uint8)\n",
    "                    else:\n",
    "                        y0,x0,y1,x1 = inst.pred_boxes[i].tensor.cpu().numpy()[0]\n",
    "                        hm[int(y0):int(y1),int(x0):int(x1)] = 1\n",
    "            human_cache[p] = letterbox_mask(hm)\n",
    "            dets = ref_det(img, candidate_labels=ref_labels, threshold=0.7)\n",
    "            mapping = {d[\"label\"].rstrip('.').lower(): d for d in dets}\n",
    "            for lbl in ref_labels:\n",
    "                key = f\"{p}|{lbl}\"\n",
    "                rm = np.zeros((H, W), dtype=np.uint8)\n",
    "                d = mapping.get(lbl)\n",
    "                if d:\n",
    "                    x0,y0 = int(d[\"box\"][\"xmin\"]), int(d[\"box\"][\"ymin\"])\n",
    "                    x1,y1 = int(d[\"box\"][\"xmax\"]), int(d[\"box\"][\"ymax\"])\n",
    "                    rm[y0:y1, x0:x1] = 1\n",
    "                ref_cache[key] = letterbox_mask(rm)\n",
    "    np.savez_compressed(HUMAN_NPZ_PATH, **human_cache)\n",
    "    np.savez_compressed(REF_NPZ_PATH, **ref_cache)\n",
    "\n",
    "class MaskOnlyDataset(Dataset):\n",
    "    def __init__(self, samples: List[Dict], ref_labels: List[str]):\n",
    "        self.samples, self.ref_labels = samples, ref_labels\n",
    "        self.h_masks = dict(np.load(HUMAN_NPZ_PATH, allow_pickle=True))\n",
    "        self.r_masks = dict(np.load(REF_NPZ_PATH, allow_pickle=True))\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        s = self.samples[idx]\n",
    "        p1,p2 = s[\"img_paths\"][:2]\n",
    "        hm1 = torch.from_numpy(self.h_masks[p1]).unsqueeze(0).float()\n",
    "        hm2 = torch.from_numpy(self.h_masks[p2]).unsqueeze(0).float()\n",
    "        rm1 = np.stack([self.r_masks[f\"{p1}|{lbl}\"] for lbl in self.ref_labels],0)\n",
    "        rm2 = np.stack([self.r_masks[f\"{p2}|{lbl}\"] for lbl in self.ref_labels],0)\n",
    "        rm1,rm2 = torch.from_numpy(rm1).float(), torch.from_numpy(rm2).float()\n",
    "        bmi = torch.tensor(float(s[\"bmi\"]), dtype=torch.float32).unsqueeze(0)\n",
    "        return hm1,hm2,rm1,rm2,bmi\n",
    "\n",
    "def get_bmi_class_new(bmi: float) -> int:\n",
    "    if bmi<17.28: return 0\n",
    "    if bmi<25.57: return 1\n",
    "    return 2\n",
    "\n",
    "class TwoViewHumanRefRes18(nn.Module):\n",
    "    def __init__(self, num_ref: int, num_classes: int=3):\n",
    "        super().__init__()\n",
    "        h18 = models.resnet18(weights=None)\n",
    "        sd = torch.load(RESNET18_PATH, map_location=\"cpu\", weights_only=False)\n",
    "        h18.load_state_dict(sd, strict=False)\n",
    "        w0 = h18.conv1.weight.data\n",
    "        h18.conv1 = nn.Conv2d(1,64,7,2,3,bias=False)\n",
    "        h18.conv1.weight.data = w0.mean(dim=1,keepdim=True)\n",
    "        self.h_backbone = nn.Sequential(*list(h18.children())[:-1])\n",
    "        r18 = models.resnet18(weights=None)\n",
    "        r18.load_state_dict(sd, strict=False)\n",
    "        w1 = r18.conv1.weight.data.mean(dim=1,keepdim=True)\n",
    "        r18.conv1 = nn.Conv2d(num_ref,64,7,2,3,bias=False)\n",
    "        r18.conv1.weight.data = w1.repeat(1,num_ref,1,1)\n",
    "        self.r_backbone = nn.Sequential(*list(r18.children())[:-1])\n",
    "        in_dim = (512+512)*2\n",
    "        self.fc_reg = nn.Linear(in_dim,1)\n",
    "        self.fc_cls = nn.Linear(in_dim,num_classes)\n",
    "    def forward(self, hm1,hm2,rm1,rm2):\n",
    "        def f(b,x): return b(x).flatten(1)\n",
    "        h1,h2 = f(self.h_backbone,hm1), f(self.h_backbone,hm2)\n",
    "        r1,r2 = f(self.r_backbone,rm1), f(self.r_backbone,rm2)\n",
    "        v1,v2 = torch.cat([h1,r1],1), torch.cat([h2,r2],1)\n",
    "        x = torch.cat([v1,v2],1)\n",
    "        return self.fc_reg(x), self.fc_cls(x)\n",
    "\n",
    "def compute_metrics(gt,pred):\n",
    "    gt,pred = np.asarray(gt),np.asarray(pred)\n",
    "    err = pred-gt\n",
    "    ks,_ = ks_2samp(gt,pred)\n",
    "    return {\n",
    "        \"r2\": r2_score(gt,pred),\n",
    "        \"mae\": mean_absolute_error(gt,pred),\n",
    "        \"tol_rate\": np.mean(np.abs(err)<=1.0),\n",
    "        \"mean_bias\": err.mean(),\n",
    "        \"error_std\": err.std(),\n",
    "        \"ks\": ks,\n",
    "        \"wasserstein\": wasserstein_distance(gt,pred),\n",
    "    }\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    with open(SAMPLE_JSON,\"r\") as f: samples=json.load(f)\n",
    "    BUILD_CACHE=False\n",
    "    if BUILD_CACHE:\n",
    "        cfg=get_cfg()\n",
    "        cfg.merge_from_file(model_zoo.get_config_file(\n",
    "          \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "        cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST=0.5\n",
    "        cfg.MODEL.WEIGHTS=model_zoo.get_checkpoint_url(\n",
    "          \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "        human_pred=DefaultPredictor(cfg)\n",
    "        ref_det=pipeline(\"zero-shot-object-detection\",\n",
    "            model=\"IDEA-Research/grounding-dino-tiny\",\n",
    "            device=0 if torch.cuda.is_available() else -1)\n",
    "        build_mask_caches(samples,human_pred,ref_det,REF_LABELS)\n",
    "        exit(0)\n",
    "\n",
    "    train=[s for s in samples if s[\"split\"]==\"Training\"]\n",
    "    val  =[s for s in samples if s[\"split\"]==\"Validation\"]\n",
    "    train_loader=DataLoader(MaskOnlyDataset(train, REF_LABELS),\n",
    "                            batch_size=8,shuffle=True,num_workers=2,pin_memory=True)\n",
    "    val_loader  =DataLoader(MaskOnlyDataset(val,   REF_LABELS),\n",
    "                            batch_size=8,shuffle=False,num_workers=2,pin_memory=True)\n",
    "\n",
    "    CHECKPOINTS   =[20,25,30,35]\n",
    "    NUM_RUNS      =3\n",
    "    EPOCHS        =35\n",
    "    weight_factors=[1,2,3,5,8]\n",
    "\n",
    "    for wf in weight_factors:\n",
    "        print(f\"\\n=== CLS weight factor = {wf} ===\")\n",
    "        metric_keys=list(compute_metrics([0],[0]).keys())+[\"cls_acc\",\n",
    "                     \"bucket_0_mae\",\"bucket_1_mae\",\"bucket_2_mae\"]\n",
    "        results={ep:{k:[] for k in metric_keys} for ep in CHECKPOINTS}\n",
    "\n",
    "        for run in range(1,NUM_RUNS+1):\n",
    "            print(f\"\\n--- Run {run} ---\")\n",
    "            model=TwoViewHumanRefRes18(num_ref=len(REF_LABELS),num_classes=3).to(DEVICE)\n",
    "            opt=optim.Adam(model.parameters(),lr=1e-4)\n",
    "            mse=nn.MSELoss()\n",
    "            cw=torch.tensor([wf,1.0,wf],device=DEVICE)\n",
    "            ce=nn.CrossEntropyLoss(weight=cw)\n",
    "\n",
    "            for ep in range(1,EPOCHS+1):\n",
    "                model.train()\n",
    "                for hm1,hm2,rm1,rm2,bmi in train_loader:\n",
    "                    hm1,hm2,rm1,rm2,bmi=[x.to(DEVICE) for x in (hm1,hm2,rm1,rm2,bmi)]\n",
    "                    labels=torch.tensor([get_bmi_class_new(b.item()) for b in bmi.flatten()],\n",
    "                                        device=DEVICE,dtype=torch.long)\n",
    "                    opt.zero_grad()\n",
    "                    out_reg,out_cls=model(hm1,hm2,rm1,rm2)\n",
    "                    loss=mse(out_reg,bmi)+ce(out_cls,labels)\n",
    "                    loss.backward(); opt.step()\n",
    "\n",
    "                if ep in CHECKPOINTS:\n",
    "                    model.eval()\n",
    "                    all_p,all_t,all_c=[],[],[]\n",
    "                    with torch.no_grad():\n",
    "                        for hm1,hm2,rm1,rm2,bmi in val_loader:\n",
    "                            hm1,hm2,rm1,rm2=[x.to(DEVICE) for x in (hm1,hm2,rm1,rm2)]\n",
    "                            p_reg,p_cls=model(hm1,hm2,rm1,rm2)\n",
    "                            all_p+=p_reg.cpu().flatten().tolist()\n",
    "                            all_t+=bmi.flatten().tolist()\n",
    "                            all_c+=torch.argmax(p_cls,dim=1).cpu().tolist()\n",
    "\n",
    "                    m=compute_metrics(all_t,all_p)\n",
    "                    acc=np.mean(np.array(all_c)==np.array([get_bmi_class_new(x) for x in all_t]))\n",
    "                    print(f\"Epoch {ep}:\",\", \".join(f\"{k}={v:.4f}\" for k,v in m.items()),\n",
    "                          f\"cls_acc={acc*100:.2f}%\")\n",
    "                    for k,v in m.items(): results[ep][k].append(v)\n",
    "                    results[ep][\"cls_acc\"].append(acc)\n",
    "\n",
    "                    errors=np.abs(np.array(all_p)-np.array(all_t))\n",
    "                    buckets=np.array([get_bmi_class_new(x) for x in all_t])\n",
    "                    bucket_mae=[(errors[buckets==b].mean() if (buckets==b).sum()>0 else np.nan)\n",
    "                                for b in (0,1,2)]\n",
    "                    results[ep][\"bucket_0_mae\"].append(bucket_mae[0])\n",
    "                    results[ep][\"bucket_1_mae\"].append(bucket_mae[1])\n",
    "                    results[ep][\"bucket_2_mae\"].append(bucket_mae[2])\n",
    "\n",
    "                    names=[\"Underweight\",\"Normal\",\"Overweight\"]\n",
    "                    plt.figure(figsize=(6,4))\n",
    "                    plt.bar(names,bucket_mae)\n",
    "                    plt.ylabel(\"MAE\"); plt.title(f\"Bucket MAE @ wf={wf}, ep={ep}\")\n",
    "                    plt.show()\n",
    "\n",
    "                    data=[errors[buckets==b] for b in (0,1,2)]\n",
    "                    plt.figure(figsize=(6,4))\n",
    "                    plt.boxplot(data,labels=names)\n",
    "                    plt.ylabel(\"Absolute Error\"); plt.title(f\"Error Dist by Bucket @ wf={wf}, ep={ep}\")\n",
    "                    plt.show()\n",
    "\n",
    "                    plt.figure(figsize=(7,6))\n",
    "                    for b,c in zip((0,1,2),(\"C0\",\"C1\",\"C2\")):\n",
    "                        mask=buckets==b\n",
    "                        plt.scatter(np.array(all_t)[mask],np.array(all_p)[mask],\n",
    "                                    alpha=0.6,label=names[b],c=c)\n",
    "                    mval,Mval=min(all_t+all_p),max(all_t+all_p)\n",
    "                    plt.plot([mval,Mval],[mval,Mval],\"k--\")\n",
    "                    plt.xlabel(\"True BMI\"); plt.ylabel(\"Pred BMI\")\n",
    "                    plt.legend(); plt.title(f\"Pred vs True @ wf={wf}, ep={ep}\")\n",
    "                    plt.show()\n",
    "\n",
    "        print(f\"\\n--- Summary for wf={wf} ---\")\n",
    "        for ep in CHECKPOINTS:\n",
    "            print(f\"\\nCheckpoint {ep}:\")\n",
    "            for k,vals in results[ep].items():\n",
    "                arr=np.array(vals)\n",
    "                if k==\"cls_acc\":\n",
    "                    print(f\"  {k:12s}{arr.mean()*100:.2f}% ± {arr.std()*100:.2f}%\")\n",
    "                else:\n",
    "                    print(f\"  {k.upper():12s}{arr.mean():.4f} ± {arr.std():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
