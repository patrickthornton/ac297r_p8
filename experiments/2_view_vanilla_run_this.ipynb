{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tI3cmG0LyB4T"
   },
   "outputs": [],
   "source": [
    "# Cell 1: setup — imports, mount, classes, dataloaders\n",
    "\n",
    "import multiprocessing\n",
    "multiprocessing.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# mount Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# --- transforms ---\n",
    "class LetterboxResize:\n",
    "    def __init__(self, size=(224, 224), fill=(0.485, 0.456, 0.406)):\n",
    "        self.size, self.fill = size, fill\n",
    "    def __call__(self, img):\n",
    "        img = ImageOps.exif_transpose(img)\n",
    "        iw, ih = img.size\n",
    "        w, h = self.size\n",
    "        scale = min(w/iw, h/ih)\n",
    "        nw, nh = int(iw*scale), int(ih*scale)\n",
    "        img = img.resize((nw, nh), Image.BICUBIC)\n",
    "        bg = Image.new('RGB', self.size, tuple(int(c*255) for c in self.fill))\n",
    "        bg.paste(img, ((w-nw)//2, (h-nh)//2))\n",
    "        return bg\n",
    "\n",
    "# --- dataset ---\n",
    "class MultiViewBMIDataset(Dataset):\n",
    "    def __init__(self, samples, transform=None):\n",
    "        self.samples, self.transform = samples, transform\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        record = self.samples[idx]\n",
    "        imgs = []\n",
    "        for p in record['img_paths'][:2]:\n",
    "            if os.path.exists(p):\n",
    "                try:\n",
    "                    img = Image.open(p).convert('RGB')\n",
    "                except:\n",
    "                    img = Image.new('RGB', (224,224), (0,0,0))\n",
    "            else:\n",
    "                img = Image.new('RGB', (224,224), (0,0,0))\n",
    "            if self.transform: img = self.transform(img)\n",
    "            imgs.append(img)\n",
    "        return imgs[0], imgs[1], float(record['bmi'])\n",
    "\n",
    "# --- model ---\n",
    "class MultiViewResNet101Baseline(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        ckpt = '/content/drive/MyDrive/resnet101-63fe2227.pth'\n",
    "        base = models.resnet101(weights=None)\n",
    "        base.load_state_dict(torch.load(ckpt, map_location='cpu'))\n",
    "        self.fe = nn.Sequential(*list(base.children())[:-1])\n",
    "        self.fc_reg = nn.Linear(2048*2, 1)\n",
    "        self.fc_cls = nn.Linear(2048*2, num_classes)\n",
    "    def forward(self, x1, x2):\n",
    "        def ext(x):\n",
    "            y = self.fe(x)\n",
    "            return y.view(y.size(0), -1)\n",
    "        f1, f2 = ext(x1), ext(x2)\n",
    "        cat = torch.cat([f1, f2], dim=1)\n",
    "        return self.fc_reg(cat), self.fc_cls(cat)\n",
    "\n",
    "# --- data loaders ---\n",
    "with open('/content/drive/MyDrive/sample_list.json','r') as f:\n",
    "    all_samples = json.load(f)\n",
    "train_samples = [s for s in all_samples if s['split']=='Training']\n",
    "val_samples   = [s for s in all_samples if s['split']=='Validation']\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    LetterboxResize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    MultiViewBMIDataset(train_samples, transform),\n",
    "    batch_size=8, shuffle=True, num_workers=0, pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    MultiViewBMIDataset(val_samples, transform),\n",
    "    batch_size=8, shuffle=False, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"train: {len(train_loader.dataset)}, val: {len(val_loader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jpuuwc4IyDIZ"
   },
   "outputs": [],
   "source": [
    "# Cell 2: train once & save checkpoint\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model  = MultiViewResNet101Baseline(num_classes=3).to(device)\n",
    "opt    = optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn= nn.MSELoss()\n",
    "epochs = 20\n",
    "\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    total = 0.0\n",
    "    t0 = time.time()\n",
    "    for x1, x2, y in train_loader:\n",
    "        x1, x2, y = x1.to(device), x2.to(device), y.to(device).unsqueeze(1)\n",
    "        opt.zero_grad()\n",
    "        pred, _ = model(x1, x2)\n",
    "        loss    = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total += loss.item()*y.size(0)\n",
    "    print(f\"Epoch {e+1}/{epochs} loss={total/len(train_loader.dataset):.4f} time={time.time()-t0:.1f}s\")\n",
    "\n",
    "# save\n",
    "ckpt_path = '/content/drive/MyDrive/multi2view_resnet101.pth'\n",
    "torch.save(model.state_dict(), ckpt_path)\n",
    "print(\"checkpoint saved to\", ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lb_FffwYyFOx"
   },
   "outputs": [],
   "source": [
    "# Cell 3: downstream tasks (model already in memory)\n",
    "\n",
    "# Load checkpoint\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Downstream Task 1: Evaluation\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "all_pred, all_true = [], []\n",
    "with torch.no_grad():\n",
    "    for x1, x2, y in val_loader:\n",
    "        x1, x2 = x1.to(device), x2.to(device)\n",
    "        p, _   = model(x1, x2)\n",
    "        all_pred += p.cpu().flatten().tolist()\n",
    "        all_true += y.flatten().tolist()\n",
    "mae = mean_absolute_error(all_true, all_pred)\n",
    "r2  = r2_score(all_true, all_pred)\n",
    "print(f\"Eval MAE={mae:.4f}, R2={r2:.4f}\")\n",
    "\n",
    "# Downstream Task 2: add more here, like determine whether 3-view is better or not\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
