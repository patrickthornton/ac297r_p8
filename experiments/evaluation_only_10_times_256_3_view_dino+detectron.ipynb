{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bIWn6j9DJtMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git'\n"
      ],
      "metadata": {
        "id": "h_fUyNRJJq9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2TdzRiGJmqL"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "multiprocessing.set_start_method(\"spawn\", force=True)\n",
        "\n",
        "import os\n",
        "import random\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageOps\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Optional, Union, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from scipy.stats import ks_2samp, wasserstein_distance\n",
        "from transformers import pipeline\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Device setup\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"DEVICE:\", DEVICE)\n",
        "\n",
        "# Configure Detectron2 for person detection\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\n",
        "    \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n",
        "    \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "person_predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# Initialize Grounding DINO pipeline\n",
        "GLOBAL_GROUNDING_DETECTOR = pipeline(\n",
        "    model=\"IDEA-Research/grounding-dino-tiny\",\n",
        "    task=\"zero-shot-object-detection\",\n",
        "    device=0 if torch.cuda.is_available() else -1\n",
        ")\n",
        "\n",
        "@dataclass\n",
        "class BoundingBox:\n",
        "    xmin: int\n",
        "    ymin: int\n",
        "    xmax: int\n",
        "    ymax: int\n",
        "\n",
        "    @property\n",
        "    def xyxy(self) -> List[float]:\n",
        "        return [self.xmin, self.ymin, self.xmax, self.ymax]\n",
        "\n",
        "@dataclass\n",
        "class DetectionResult:\n",
        "    score: float\n",
        "    label: str\n",
        "    box: BoundingBox\n",
        "    mask: Optional[np.ndarray] = None\n",
        "\n",
        "    @classmethod\n",
        "    def from_dict(cls, d: Dict) -> 'DetectionResult':\n",
        "        return cls(\n",
        "            score=d['score'],\n",
        "            label=d['label'],\n",
        "            box=BoundingBox(\n",
        "                xmin=int(d['box']['xmin']),\n",
        "                ymin=int(d['box']['ymin']),\n",
        "                xmax=int(d['box']['xmax']),\n",
        "                ymax=int(d['box']['ymax'])\n",
        "            )\n",
        "        )\n",
        "\n",
        "def grounded_segmentation(image: Union[Image.Image, str],\n",
        "                          labels: List[str],\n",
        "                          threshold: float = 0.7) -> Tuple[np.ndarray, List[DetectionResult]]:\n",
        "    if isinstance(image, str):\n",
        "        image = Image.open(image).convert(\"RGB\")\n",
        "    image = ImageOps.exif_transpose(image)\n",
        "    labels = [lbl if lbl.endswith('.') else lbl + '.' for lbl in labels]\n",
        "    results = GLOBAL_GROUNDING_DETECTOR(image, candidate_labels=labels, threshold=threshold)\n",
        "    detections = [DetectionResult.from_dict(r) for r in results]\n",
        "    return np.array(image), detections\n",
        "\n",
        "def compute_view_features(img: Image.Image, ref_labels: List[str]) -> np.ndarray:\n",
        "    W, H = img.width, img.height\n",
        "    _, detections = grounded_segmentation(img, ref_labels, threshold=0.7)\n",
        "    feats_ref = []\n",
        "    for label in ref_labels:\n",
        "        matched = [d for d in detections if d.label.strip('.').lower() == label.strip('.').lower()]\n",
        "        if matched:\n",
        "            best = max(matched, key=lambda d: d.score)\n",
        "            bx, by, xx, yy = best.box.xyxy\n",
        "            area = (xx - bx) * (yy - by)\n",
        "            feats_ref += [1.0, area / (W * H)]\n",
        "        else:\n",
        "            feats_ref += [0.0, 0.0]\n",
        "    img_np = np.array(img)\n",
        "    outputs = person_predictor(cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR))\n",
        "    inst = outputs[\"instances\"]\n",
        "    human_ratio = 0.0\n",
        "    if len(inst) > 0:\n",
        "        idxs = (inst.pred_classes == 0).nonzero().squeeze()\n",
        "        if idxs.numel() > 0:\n",
        "            if idxs.ndim == 0:\n",
        "                i = idxs.item()\n",
        "            else:\n",
        "                scores = inst.scores[idxs]\n",
        "                i = idxs[scores.argmax()]\n",
        "            if inst.has(\"pred_masks\") and len(inst.pred_masks) > i:\n",
        "                m = inst.pred_masks[i].cpu().numpy().astype(np.uint8)\n",
        "                human_ratio = m.sum() / (W * H)\n",
        "            else:\n",
        "                bx0, by0, bx1, by1 = inst.pred_boxes[i].tensor.cpu().numpy()[0]\n",
        "                human_ratio = ((bx1 - bx0) * (by1 - by0)) / (W * H)\n",
        "    return np.array(feats_ref + [human_ratio], dtype=np.float32)\n",
        "\n",
        "def offline_precompute_features_chunked(samples: List[dict],\n",
        "                                        cache_path: str,\n",
        "                                        ref_labels: List[str] = [\"a black paper\", \"a white ball\"],\n",
        "                                        chunk_size: int = 30):\n",
        "    feat_dim = 5 * 3\n",
        "    cache = np.zeros((len(samples), feat_dim), dtype=np.float32)\n",
        "    start = 0\n",
        "    while start < len(samples):\n",
        "        end = min(start + chunk_size, len(samples))\n",
        "        chunk = samples[start:end]\n",
        "        paths = []\n",
        "        index_map = []\n",
        "        for i, s in enumerate(chunk):\n",
        "            for j in range(3):\n",
        "                paths.append(s[\"img_paths\"][j])\n",
        "                index_map.append((i, j))\n",
        "        images = []\n",
        "        for p in paths:\n",
        "            if os.path.exists(p):\n",
        "                try:\n",
        "                    images.append(Image.open(p).convert(\"RGB\"))\n",
        "                except:\n",
        "                    images.append(None)\n",
        "            else:\n",
        "                images.append(None)\n",
        "        feats = [[None]*3 for _ in chunk]\n",
        "        for img, (i, j) in zip(images, index_map):\n",
        "            if img is None:\n",
        "                feats[i][j] = np.zeros(5, dtype=np.float32)\n",
        "            else:\n",
        "                feats[i][j] = compute_view_features(img, ref_labels)\n",
        "        for i in range(len(chunk)):\n",
        "            cache[start + i] = np.concatenate(feats[i], axis=0)\n",
        "        start = end\n",
        "    np.save(cache_path, cache)\n",
        "    print(\"Features cached to\", cache_path)\n",
        "\n",
        "class LetterboxResize:\n",
        "    def __init__(self, size=(224,224), fill=(0.485,0.456,0.406)):\n",
        "        self.size, self.fill = size, fill\n",
        "    def __call__(self, img):\n",
        "        img = ImageOps.exif_transpose(img)\n",
        "        iw, ih = img.size\n",
        "        w, h = self.size\n",
        "        scale = min(w/iw, h/ih)\n",
        "        nw, nh = int(iw*scale), int(ih*scale)\n",
        "        img = img.resize((nw,nh), Image.BICUBIC)\n",
        "        bg = Image.new(\"RGB\", self.size, tuple(int(c*255) for c in self.fill))\n",
        "        bg.paste(img, ((w-nw)//2, (h-nh)//2))\n",
        "        return bg\n",
        "\n",
        "class MultiViewBMIWithRefDataset(Dataset):\n",
        "    def __init__(self, samples, feats, transform=None):\n",
        "        self.samples, self.feats, self.transform = samples, feats, transform\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "    def __getitem__(self, idx):\n",
        "        s = self.samples[idx]\n",
        "        imgs = []\n",
        "        for j in range(3):\n",
        "            p = s[\"img_paths\"][j]\n",
        "            if os.path.exists(p):\n",
        "                try:\n",
        "                    img = Image.open(p).convert(\"RGB\")\n",
        "                except:\n",
        "                    img = Image.new(\"RGB\", (224,224), (0,0,0))\n",
        "            else:\n",
        "                img = Image.new(\"RGB\", (224,224), (0,0,0))\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "            imgs.append(img)\n",
        "        ref = torch.tensor(self.feats[idx], dtype=torch.float32)\n",
        "        bmi = torch.tensor(float(s[\"bmi\"]), dtype=torch.float32)\n",
        "        return imgs[0], imgs[1], imgs[2], ref, bmi\n",
        "\n",
        "class FusedMultiViewBMIModel(nn.Module):\n",
        "    def __init__(self, ref_dim=256, num_classes=4):\n",
        "        super().__init__()\n",
        "        base = models.resnet101(weights=None)\n",
        "        base.load_state_dict(torch.load(\n",
        "            \"/content/drive/MyDrive/resnet101-63fe2227.pth\",\n",
        "            map_location=DEVICE))\n",
        "        self.backbone = nn.Sequential(*list(base.children())[:-1])\n",
        "        self.ref_proj = nn.Sequential(nn.Linear(15, ref_dim), nn.ReLU())\n",
        "        self.fc_reg = nn.Linear(2048*3 + ref_dim, 1)\n",
        "        self.fc_cls = nn.Linear(2048*3 + ref_dim, num_classes)\n",
        "    def forward(self, x0, x1, x2, ref):\n",
        "        def ext(x):\n",
        "            y = self.backbone(x)\n",
        "            return y.view(y.size(0), -1)\n",
        "        f0, f1, f2 = ext(x0), ext(x1), ext(x2)\n",
        "        cnn = torch.cat([f0, f1, f2], dim=1)\n",
        "        r = self.ref_proj(ref)\n",
        "        allf = torch.cat([cnn, r], dim=1)\n",
        "        return self.fc_reg(allf), self.fc_cls(allf)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    sample_json = \"/content/drive/MyDrive/sample_list.json\"\n",
        "    cache_npy   = \"/content/drive/MyDrive/features_cache_3view.npy\"\n",
        "    ref_labels  = [\"a black paper\", \"a white ball\"]\n",
        "\n",
        "    with open(sample_json) as f:\n",
        "        samples = json.load(f)\n",
        "\n",
        "    if not os.path.exists(cache_npy):\n",
        "        offline_precompute_features_chunked(samples, cache_npy, ref_labels, chunk_size=30)\n",
        "    feats = np.load(cache_npy)\n",
        "\n",
        "    train_s = [s for s in samples if s[\"split\"]==\"Training\"]\n",
        "    val_s   = [s for s in samples if s[\"split\"]==\"Validation\"]\n",
        "    train_idx = [i for i, s in enumerate(samples) if s[\"split\"]==\"Training\"]\n",
        "    val_idx   = [i for i, s in enumerate(samples) if s[\"split\"]==\"Validation\"]\n",
        "    train_f = feats[train_idx]\n",
        "    val_f   = feats[val_idx]\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        LetterboxResize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ])\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        MultiViewBMIWithRefDataset(train_s, train_f, transform),\n",
        "        batch_size=8, shuffle=True, num_workers=0, pin_memory=True\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        MultiViewBMIWithRefDataset(val_s, val_f, transform),\n",
        "        batch_size=8, shuffle=False, num_workers=0, pin_memory=True\n",
        "    )\n",
        "\n",
        "    print(f\"Train: {len(train_loader.dataset)}, Val: {len(val_loader.dataset)}\")\n",
        "\n",
        "    checkpoint_epochs = [20,25,30,35]\n",
        "    max_epoch = max(checkpoint_epochs)\n",
        "    num_runs  = 5\n",
        "\n",
        "    results = {ep: {k:[] for k in ['r2','mae','tol_rate','mean_bias','error_std','ks','wasserstein']}\n",
        "               for ep in checkpoint_epochs}\n",
        "\n",
        "    for run in range(1, num_runs+1):\n",
        "        print(f\"\\n=== Run {run}/{num_runs} ===\")\n",
        "        model = FusedMultiViewBMIModel(ref_dim=256, num_classes=4).to(DEVICE)\n",
        "        opt   = optim.Adam(model.parameters(), lr=1e-4)\n",
        "        loss_fn = nn.MSELoss()\n",
        "\n",
        "        for epoch in range(1, max_epoch+1):\n",
        "            t0, tloss = time.time(), 0.0\n",
        "            model.train()\n",
        "            for x0, x1, x2, ref, bmi in train_loader:\n",
        "                x0, x1, x2 = x0.to(DEVICE), x1.to(DEVICE), x2.to(DEVICE)\n",
        "                ref, bmi   = ref.to(DEVICE), bmi.to(DEVICE).unsqueeze(1)\n",
        "                opt.zero_grad()\n",
        "                pred, _ = model(x0, x1, x2, ref)\n",
        "                loss = loss_fn(pred, bmi)\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "                tloss += loss.item() * bmi.size(0)\n",
        "            print(f\"Epoch {epoch}/{max_epoch} loss={tloss/len(train_loader.dataset):.4f} time={time.time()-t0:.1f}s\")\n",
        "\n",
        "            if epoch in checkpoint_epochs:\n",
        "                model.eval()\n",
        "                preds, trues = [], []\n",
        "                with torch.no_grad():\n",
        "                    for x0, x1, x2, ref, bmi in val_loader:\n",
        "                        x0, x1, x2 = x0.to(DEVICE), x1.to(DEVICE), x2.to(DEVICE)\n",
        "                        ref, bmi   = ref.to(DEVICE), bmi.to(DEVICE).unsqueeze(1)\n",
        "                        p, _ = model(x0, x1, x2, ref)\n",
        "                        preds += p.cpu().flatten().tolist()\n",
        "                        trues += bmi.cpu().flatten().tolist()\n",
        "                gt = np.array(trues)\n",
        "                pr = np.array(preds)\n",
        "                r2v  = r2_score(gt, pr)\n",
        "                maev = mean_absolute_error(gt, pr)\n",
        "                tol  = np.mean(np.abs(gt-pr) <= 1.0)\n",
        "                bias = np.mean(pr-gt)\n",
        "                std  = np.std(pr-gt)\n",
        "                ks_v = ks_2samp(gt, pr)[0]\n",
        "                ws   = wasserstein_distance(gt, pr)\n",
        "                print(f\"[cp {epoch}] R2={r2v:.4f}, MAE={maev:.4f}, tol_rate={tol:.2%}\")\n",
        "                res = results[epoch]\n",
        "                res['r2'].append(r2v)\n",
        "                res['mae'].append(maev)\n",
        "                res['tol_rate'].append(tol)\n",
        "                res['mean_bias'].append(bias)\n",
        "                res['error_std'].append(std)\n",
        "                res['ks'].append(ks_v)\n",
        "                res['wasserstein'].append(ws)\n",
        "\n",
        "    print(\"\\n=== Summary ===\")\n",
        "    for ep in checkpoint_epochs:\n",
        "        print(f\"\\nEpoch {ep}:\")\n",
        "        for k, v in results[ep].items():\n",
        "            print(f\"  {k}: mean={np.mean(v):.4f}, std={np.std(v):.4f}\")\n"
      ]
    }
  ]
}