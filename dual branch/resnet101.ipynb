{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVBqvm6wVHzQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the Dataset class\n",
        "class BMIDataset(Dataset):\n",
        "    def __init__(self, folder, transform=None):\n",
        "        self.folder = folder\n",
        "        self.image_files = [f for f in os.listdir(folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_files[idx]\n",
        "        img_path = os.path.join(self.folder, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        match = re.match(r\"\\d+?_([FMfm])_(\\d+?)_(\\d+?)_(\\d+).+\", img_name)\n",
        "        if match:\n",
        "            height = int(match.group(3)) / 100000  # convert mm to m\n",
        "            weight = int(match.group(4)) / 100000  # convert mg to kg\n",
        "            bmi = weight / (height ** 2)\n",
        "        else:\n",
        "            bmi = 0.0\n",
        "        return image, float(bmi)\n",
        "\n",
        "# Define the transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Set the folder paths\n",
        "train_folder = \"/content/drive/MyDrive/Image_train/\"\n",
        "val_folder = \"/content/drive/MyDrive/Image_val/\"\n",
        "# train_folder = \"/content/drive/MyDrive/Image_train_gaussian_15/\"\n",
        "# val_folder = \"/content/drive/MyDrive/Image_val_gaussian_15/\"\n",
        "# train_folder = \"/content/drive/MyDrive/Image_train_gaussian_30/\"\n",
        "# val_folder = \"/content/drive/MyDrive/Image_val_gaussian_30/\"\n",
        "# train_folder = \"/content/drive/MyDrive/Image_train_rotate_10/\"\n",
        "# val_folder = \"/content/drive/MyDrive/Image_val_rotate_10/\"\n",
        "# train_folder = \"/content/drive/MyDrive/Image_train_rotate_20/\"\n",
        "# val_folder = \"/content/drive/MyDrive/Image_val_rotate_20/\"\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = BMIDataset(train_folder, transform=transform)\n",
        "val_dataset = BMIDataset(val_folder, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
        "\n",
        "# Build the ResNet101 model for regression\n",
        "model = models.resnet101(pretrained=True)\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 1)\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, targets in train_loader:\n",
        "        images = images.to(DEVICE)\n",
        "        targets = targets.to(DEVICE).unsqueeze(1).float()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "# Evaluation on validation set\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "with torch.no_grad():\n",
        "    for images, targets in val_loader:\n",
        "        images = images.to(DEVICE)\n",
        "        targets = targets.to(DEVICE).unsqueeze(1).float()\n",
        "        outputs = model(images)\n",
        "        all_preds.extend(outputs.cpu().numpy().flatten().tolist())\n",
        "        all_targets.extend(targets.cpu().numpy().flatten().tolist())\n",
        "\n",
        "mae_val = mean_absolute_error(all_targets, all_preds)\n",
        "print(f\"Validation MAE: {mae_val:.4f}\")\n"
      ],
      "metadata": {
        "id": "DbltQe4xWC8B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}