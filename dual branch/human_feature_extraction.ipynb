{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mvEVuCxHkbE"
      },
      "outputs": [],
      "source": [
        "!pip install ninja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0BFL1KUcaTd"
      },
      "outputs": [],
      "source": [
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imewuHRWHp9N"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/PeikeLi/Self-Correction-Human-Parsing\n",
        "%cd Self-Correction-Human-Parsing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziz8nQMWHsYm"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader\n",
        "sys.path.append('/content/Self-Correction-Human-Parsing')\n",
        "import networks\n",
        "from utils.transforms import transform_logits\n",
        "from datasets.simple_extractor_dataset import SimpleFolderDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8smtriMRty4"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# init_file = \"/content/Self-Correction-Human-Parsing/networks/__init__.py\"\n",
        "# if not os.path.exists(init_file):\n",
        "#     open(init_file, 'w').close()\n",
        "# print(\" __init__.py\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15Wz6F_eZ7ge"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZ3OSE7_NikD"
      },
      "outputs": [],
      "source": [
        "# pth_path = \"/content/drive/MyDrive/singleimg models/exp-schp-201908261155-lip.pth\"\n",
        "pth_path = \"/content/drive/MyDrive/singleimg models/exp-schp-201908270938-pascal-person-part.pth\"\n",
        "\n",
        "checkpoint = torch.load(pth_path)\n",
        "print(checkpoint.keys())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mqny1LKwyrx4"
      },
      "outputs": [],
      "source": [
        "def get_palette(num_cls):\n",
        "    n = num_cls\n",
        "    palette = [0] * (n * 3)\n",
        "    for j in range(0, n):\n",
        "        lab = j\n",
        "        palette[j * 3 + 0] = 0\n",
        "        palette[j * 3 + 1] = 0\n",
        "        palette[j * 3 + 2] = 0\n",
        "        i = 0\n",
        "        while lab:\n",
        "            palette[j * 3 + 0] |= (((lab >> 0) & 1) << (7 - i))\n",
        "            palette[j * 3 + 1] |= (((lab >> 1) & 1) << (7 - i))\n",
        "            palette[j * 3 + 2] |= (((lab >> 2) & 1) << (7 - i))\n",
        "            i += 1\n",
        "            lab >>= 3\n",
        "    return palette\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdn8kiBRKJdk"
      },
      "outputs": [],
      "source": [
        "\n",
        "input_dir = \"/content/drive/MyDrive/Image_train\"\n",
        "img_name = \"001186_M_28_175260_5896701.png\"\n",
        "\n",
        "dataset_name = \"pascal\"\n",
        "dataset_settings = {\n",
        "    'lip': {\n",
        "        'input_size': [473, 473],\n",
        "        'num_classes': 20,\n",
        "        'label': ['Background', 'Hat', 'Hair', 'Glove', 'Sunglasses',\n",
        "                  'Upper-clothes', 'Dress', 'Coat', 'Socks', 'Pants',\n",
        "                  'Jumpsuits', 'Scarf', 'Skirt', 'Face', 'Left-arm',\n",
        "                  'Right-arm', 'Left-leg', 'Right-leg', 'Left-shoe', 'Right-shoe']\n",
        "    },\n",
        "    'pascal': {\n",
        "        'input_size': [512, 512],\n",
        "        'num_classes': 7,\n",
        "        'label': ['Background', 'Head', 'Torso', 'Upper Arms', 'Lower Arms', 'Upper Legs', 'Lower Legs'],\n",
        "    }\n",
        "}\n",
        "\n",
        "input_size = dataset_settings[dataset_name]['input_size']\n",
        "num_classes = dataset_settings[dataset_name]['num_classes']\n",
        "label_list = dataset_settings[dataset_name]['label']\n",
        "\n",
        "\n",
        "print(\"construct...\")\n",
        "model = networks.init_model('resnet101', num_classes=num_classes, pretrained=None)\n",
        "\n",
        "state_dict = torch.load(pth_path, map_location=\"cpu\")['state_dict']\n",
        "from collections import OrderedDict\n",
        "new_state_dict = OrderedDict()\n",
        "for k, v in state_dict.items():\n",
        "    name = k[7:] if k.startswith(\"module.\") else k\n",
        "    new_state_dict[name] = v\n",
        "model.load_state_dict(new_state_dict)\n",
        "model.eval()\n",
        "model.cuda()\n",
        "print(\"loaded \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBXpKRfN72Ur"
      },
      "outputs": [],
      "source": [
        "class HumanParser(object):\n",
        "    def __init__(self, model = model, input_sizee = [473, 473], num_classes = 20):\n",
        "        self.model = torch.nn.DataParallel(model).cuda()\n",
        "        self.model.eval()\n",
        "        self.input_size = input_size\n",
        "        self.num_classes = num_classes\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.406, 0.456, 0.485],\n",
        "                                 std=[0.225, 0.224, 0.229])\n",
        "        ])\n",
        "\n",
        "    def Arms_detect(self, img):\n",
        "        # print(\"debug!\")\n",
        "        # print(\"Arms_detect received:\", type(img))\n",
        "        # if isinstance(img, np.ndarray):\n",
        "        #    img = torch.from_numpy(img)\n",
        "        h, w, _ = img.shape\n",
        "        aspect_ratio = self.input_size[1] * 1.0 / self.input_size[0]\n",
        "        person_center, s = self.box2cs([0, 0, w - 1, h - 1], aspect_ratio)\n",
        "        r = 0\n",
        "        trans = self.get_affine_transform(person_center, s, r, self.input_size)\n",
        "        warped = cv2.warpAffine(\n",
        "            img,\n",
        "            trans,\n",
        "            (int(self.input_size[1]), int(self.input_size[0])),\n",
        "            flags=cv2.INTER_LINEAR,\n",
        "            borderMode=cv2.BORDER_CONSTANT,\n",
        "            borderValue=(0, 0, 0)\n",
        "        )\n",
        "        warped = cv2.cvtColor(warped, cv2.COLOR_BGR2RGB)\n",
        "        input_tensor = self.transform(warped).unsqueeze(dim=0)\n",
        "        output = self.model(input_tensor.cuda())\n",
        "        # print([type(o) for o in output], [[o.shape if isinstance(o, torch.Tensor) else \"list\" for o in group] for group in output])\n",
        "\n",
        "        # parsing_result = output[0][0]\n",
        "        # plt.imshow(parsing_result.detach().cpu().numpy()[0], cmap=\"gray\")\n",
        "        # plt.title(\"Parsing Result1\")\n",
        "        # plt.axis(\"off\")\n",
        "        # plt.show()\n",
        "        parsing_result = output[0][1]\n",
        "        # plt.imshow(parsing_result.detach().cpu().numpy()[0], cmap=\"gray\")\n",
        "        # plt.title(\"Parsing Result2\")\n",
        "        # plt.axis(\"off\")\n",
        "        # plt.show()\n",
        "\n",
        "        if not isinstance(parsing_result, torch.Tensor):\n",
        "            raise TypeError(f\"Expected Tensor, but got {type(parsing_result)}\")\n",
        "        upsample_output = torch.nn.functional.interpolate(parsing_result, size=self.input_size, mode='bilinear', align_corners=True)\n",
        "        # upsample_output = upsample(output)\n",
        "        upsample_output = upsample_output.squeeze()\n",
        "        upsample_output = upsample_output.permute(1, 2, 0)  # CHW -> HWC\n",
        "        upsample_output = upsample_output.data.cpu().numpy()\n",
        "        trans = self.get_affine_transform(person_center, s, 0, self.input_size, inv=1)\n",
        "        channel = upsample_output.shape[2]\n",
        "        target_logits = []\n",
        "        for i in range(channel):\n",
        "            target_logit = cv2.warpAffine(\n",
        "                upsample_output[:, :, i],\n",
        "                trans,\n",
        "                (int(w), int(h)),  # (int(width), int(height)),\n",
        "                flags=cv2.INTER_LINEAR,\n",
        "                borderMode=cv2.BORDER_CONSTANT,\n",
        "                borderValue=(0)\n",
        "            )\n",
        "            target_logits.append(target_logit)\n",
        "        target_logits = np.stack(target_logits, axis=2)\n",
        "        parsing_result = np.argmax(target_logits, axis=2)\n",
        "        # result = list(map(lambda x: list(map(lambda y: y == 14 or y == 15, x)), parsing_result))\n",
        "        result = list(map(lambda x: list(map(lambda y: y == 3 or y == 4, x)), parsing_result))\n",
        "        result = np.asarray(result)\n",
        "        # print(result.shape)\n",
        "        return result\n",
        "\n",
        "    def get_3rd_point(self, a, b):\n",
        "        direct = a - b\n",
        "        return b + np.array([-direct[1], direct[0]], dtype=np.float32)\n",
        "\n",
        "    def get_dir(self, src_point, rot_rad):\n",
        "        sn, cs = np.sin(rot_rad), np.cos(rot_rad)\n",
        "        src_result = [src_point[0] * cs - src_point[1] * sn,\n",
        "                      src_point[0] * sn + src_point[1] * cs]\n",
        "        return src_result\n",
        "\n",
        "    def get_affine_transform(self, center, scale, rot, output_size, shift=np.array([0, 0], dtype=np.float32), inv=0):\n",
        "        if not isinstance(scale, np.ndarray) and not isinstance(scale, list):\n",
        "            scale = np.array([scale, scale], dtype=np.float32)\n",
        "        src_w = scale[0]\n",
        "        dst_w = output_size[1]\n",
        "        dst_h = output_size[0]\n",
        "        rot_rad = np.pi * rot / 180\n",
        "        src_dir = self.get_dir([0, src_w * -0.5], rot_rad)\n",
        "        dst_dir = np.array([0, (dst_w - 1) * -0.5], np.float32)\n",
        "        src = np.zeros((3, 2), dtype=np.float32)\n",
        "        dst = np.zeros((3, 2), dtype=np.float32)\n",
        "        src[0, :] = center + scale * shift\n",
        "        src[1, :] = center + src_dir + scale * shift\n",
        "        dst[0, :] = [ (dst_w - 1) * 0.5, (dst_h - 1) * 0.5 ]\n",
        "        dst[1, :] = [ (dst_w - 1) * 0.5, (dst_h - 1) * 0.5 ] + dst_dir\n",
        "        src[2, :] = self.get_3rd_point(src[0, :], src[1, :])\n",
        "        dst[2, :] = self.get_3rd_point(dst[0, :], dst[1, :])\n",
        "        if inv:\n",
        "            trans = cv2.getAffineTransform(np.float32(dst), np.float32(src))\n",
        "        else:\n",
        "            trans = cv2.getAffineTransform(np.float32(src), np.float32(dst))\n",
        "        return trans\n",
        "\n",
        "    def box2cs(self, box, ar):\n",
        "        x, y, w, h = box[:4]\n",
        "        return self.xywh2cs(x, y, w, h, ar)\n",
        "\n",
        "    def xywh2cs(self, x, y, w, h, ar):\n",
        "        center = np.zeros(2, dtype=np.float32)\n",
        "        center[0] = x + w * 0.5\n",
        "        center[1] = y + h * 0.5\n",
        "        if w > ar * h:\n",
        "            h = w * 1.0 / ar\n",
        "        elif w < ar * h:\n",
        "            w = h * ar\n",
        "        scale = np.array([w, h], dtype=np.float32)\n",
        "        return center, scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1OusxWPCnNA"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/singleimg models/modeling')\n",
        "sys.path.append('/content/drive/MyDrive/singleimg models')\n",
        "sys.path.append('/content/drive/MyDrive/singleimg models/lib')\n",
        "sys.path.append('/content/drive/MyDrive/singleimg models/lib/transforms')\n",
        "\n",
        "from build_model import Pose2Seg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FvUJWTihdVo"
      },
      "outputs": [],
      "source": [
        "import detectron2\n",
        "print(detectron2.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpQizPJUCnPI"
      },
      "outputs": [],
      "source": [
        "class Body_Figure(object):\n",
        "    def __init__(self, waist_width, thigh_width, hip_width, head_width, Area, height, shoulder_width):\n",
        "        self._waist_width = waist_width\n",
        "        self._thigh_width = thigh_width\n",
        "        self._hip_width = hip_width\n",
        "        self._head_width = head_width\n",
        "        self._Area = Area\n",
        "        self._height = height\n",
        "        self._shoulder_width = shoulder_width\n",
        "        if self._head_width == 0:\n",
        "            self._head_width = self._hip_width / 3\n",
        "\n",
        "    @property\n",
        "    def WSR(self):\n",
        "        return self._waist_width / self._shoulder_width\n",
        "\n",
        "    @property\n",
        "    def WTR(self):\n",
        "        return self._waist_width / self._thigh_width\n",
        "\n",
        "    @property\n",
        "    def WHpR(self):\n",
        "        return self._waist_width / self._hip_width\n",
        "\n",
        "    @property\n",
        "    def WHdR(self):\n",
        "        return self._waist_width / self._head_width\n",
        "\n",
        "    @property\n",
        "    def HpHdR(self):\n",
        "        return self._hip_width / self._head_width\n",
        "\n",
        "    @property\n",
        "    def Area(self):\n",
        "        return self._Area\n",
        "\n",
        "    @property\n",
        "    def H2W(self):\n",
        "        return self._height / self._waist_width\n",
        "\n",
        "\n",
        "class Image_Processor(object):\n",
        "\n",
        "    def __init__(self, masks_file, key_file, key_thresh=0.7):\n",
        "        self._KeypointCfg = self.__init_key(key_file, key_thresh)\n",
        "        self._ContourPredictor = self.__init_mask(masks_file)\n",
        "        self._KeypointsPredictor = DefaultPredictor(self._KeypointCfg)\n",
        "        self._HumanParser = HumanParser()\n",
        "        print(\"check\")\n",
        "\n",
        "    def __init_mask_RCNN(self):\n",
        "        cfg = get_cfg()\n",
        "\n",
        "        cfg.merge_from_file(model_zoo.get_config_file('COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml'))\n",
        "        cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "        cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "        return cfg\n",
        "\n",
        "    def __init_mask(self, masks_file):\n",
        "        Model = Pose2Seg().cuda()\n",
        "        Model.init(masks_file)\n",
        "        Model.eval()\n",
        "        return Model\n",
        "    # num not match wtf\n",
        "    # def __init_key(self, key_file, key_thresh):\n",
        "    #     cfg = get_cfg()\n",
        "    #     cfg.MODEL.DEVICE = \"cuda\"\n",
        "    #     cfg.merge_from_file(model_zoo.get_config_file(key_file))\n",
        "    #     cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = key_thresh\n",
        "    #     cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(key_file)\n",
        "    #     return cfg\n",
        "    def __init_key(self, key_file, key_thresh):\n",
        "      cfg = get_cfg()\n",
        "      cfg.merge_from_file(model_zoo.get_config_file(key_file))\n",
        "      cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = key_thresh\n",
        "      cfg.MODEL.DEVICE = \"cuda\"\n",
        "      cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(key_file)\n",
        "\n",
        "      model = DefaultPredictor(cfg).model\n",
        "      detectron2.checkpoint.DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)\n",
        "\n",
        "      return cfg\n",
        "\n",
        "    def _detected(self, img):\n",
        "        # Mask RCNN\n",
        "        KeypointsOutput = self._KeypointsPredictor(img)\n",
        "        sorted_idxs = np.argsort(-KeypointsOutput[\"instances\"].scores.cpu().numpy())\n",
        "        Keypoints = KeypointsOutput[\"instances\"].pred_keypoints[sorted_idxs[0]].cpu().numpy()\n",
        "        gt_kpts = Keypoints[None, :, :]\n",
        "\n",
        "        # Pose2Seg\n",
        "        ContourOutput = self._ContourPredictor([img], [gt_kpts])\n",
        "        ContourOutput = np.squeeze(np.asarray(ContourOutput))\n",
        "        # plt.figure(figsize=(10,5))\n",
        "\n",
        "        # plt.subplot(1,2,1)\n",
        "        # plt.imshow(ContourOutput, cmap=\"gray\")\n",
        "        # plt.title(\"before remove arms\")\n",
        "\n",
        "\n",
        "        Arms_mask = self._HumanParser.Arms_detect(img)\n",
        "        ContourOutput = ContourOutput ^ Arms_mask\n",
        "        # plt.subplot(1,2,2)\n",
        "        # plt.imshow(ContourOutput, cmap=\"gray\")\n",
        "        # plt.title(\"after remove arms\")\n",
        "\n",
        "        # plt.show()\n",
        "        return Keypoints, ContourOutput\n",
        "\n",
        "    def Process(self, img_RGB):\n",
        "        img_keypoints, img_mask = self._detected(img_RGB)\n",
        "        nose, left_eye, right_eye, left_ear, right_ear = img_keypoints[0], img_keypoints[1], img_keypoints[2], img_keypoints[3], img_keypoints[4]\n",
        "        left_shoulder, right_shoulder = img_keypoints[5], img_keypoints[6]\n",
        "        left_elbow, right_elbow = img_keypoints[7], img_keypoints[8]\n",
        "        left_wrist, right_wrist = img_keypoints[9], img_keypoints[10]\n",
        "        left_hip, right_hip = img_keypoints[11], img_keypoints[12]\n",
        "        left_knee, right_knee = img_keypoints[13], img_keypoints[14]\n",
        "        left_ankle, right_ankle = img_keypoints[15], img_keypoints[16]\n",
        "\n",
        "\n",
        "        y_hip = (left_hip[1] + right_hip[1]) / 2\n",
        "        y_knee = (left_knee[1] + right_knee[1]) / 2\n",
        "\n",
        "        center_shoulder = (left_shoulder + right_shoulder) / 2\n",
        "        y_waist = y_hip * 2 / 3 + (nose[1] + center_shoulder[1]) / 6\n",
        "        left_thigh = (left_knee + left_hip) / 2\n",
        "        right_thigh = (right_knee + right_hip) / 2\n",
        "\n",
        "        waist_width = self.waist_width_estimate(center_shoulder, y_waist, img_mask)\n",
        "        thigh_width = self.thigh_width_estimate(left_thigh, right_thigh, img_mask)\n",
        "        hip_width = self.hip_width_estimate(center_shoulder, y_hip, img_mask)\n",
        "        head_width = self.head_width_estimate(left_ear, right_ear)\n",
        "        Area = self.Area_estimate(y_waist, y_hip, waist_width, hip_width, img_mask)\n",
        "        height = self.Height_estimate(y_knee, nose[1])\n",
        "        shoulder_width = self.shoulder_width_estimate(left_shoulder, right_shoulder)\n",
        "\n",
        "        figure = Body_Figure(waist_width, thigh_width, hip_width, head_width, Area, height, shoulder_width)\n",
        "        return figure\n",
        "\n",
        "    def Height_estimate(self, y_k, y_n):\n",
        "        return np.abs(y_n - y_k)\n",
        "\n",
        "    def Area_estimate(self, y_w, y_h, W_w, H_w, mask):\n",
        "        pixels = np.sum(mask[int(y_w):int(y_h)][:])\n",
        "        area = (y_h - y_w) * 0.5 * (W_w + H_w)\n",
        "        return pixels / area\n",
        "\n",
        "    def shoulder_width_estimate(self, left_shoulder, right_shoulder):\n",
        "        return np.sqrt((right_shoulder[0] - left_shoulder[0]) ** 2 + (right_shoulder[1] - left_shoulder[1]) ** 2)\n",
        "\n",
        "    def head_width_estimate(self, left_ear, right_ear):\n",
        "        return np.sqrt((right_ear[0] - left_ear[0]) ** 2 + (right_ear[1] - left_ear[1]) ** 2)\n",
        "\n",
        "    def hip_width_estimate(self, center_shoulder, y_hip, img_mask):\n",
        "        x_hip_center = int(center_shoulder[0])\n",
        "        x_lhb = np.where(img_mask[int(y_hip)][:x_hip_center] == 0)[0]\n",
        "        x_lhb = x_lhb[-1] if len(x_lhb) else 0\n",
        "        x_rhb = np.where(img_mask[int(y_hip)][x_hip_center:] == 0)[0]\n",
        "        x_rhb = x_rhb[0] + x_hip_center if len(x_rhb) else len(img_mask[0])\n",
        "        return x_rhb - x_lhb\n",
        "\n",
        "    def thigh_width_estimate(self, left_thigh, right_thigh, mask):\n",
        "        lx, ly = int(left_thigh[0]), int(left_thigh[1])\n",
        "        rx, ry = int(right_thigh[0]), int(right_thigh[1])\n",
        "        x_ltb = np.where(mask[ly][:lx] == 0)[0]\n",
        "        x_ltb = x_ltb[-1] if len(x_ltb) else 0\n",
        "        x_rtb = np.where(mask[ry][rx:] == 0)[0]\n",
        "        x_rtb = x_rtb[0] + rx if len(x_rtb) else len(mask[0])\n",
        "        l_width = (lx - x_ltb) * 2\n",
        "        r_width = (x_rtb - rx) * 2\n",
        "        return (l_width + r_width) / 2\n",
        "\n",
        "    def waist_width_estimate(self, center_shoulder, y_waist, img_mask):\n",
        "        x_waist_center = int(center_shoulder[0])\n",
        "        x_lwb = np.where(img_mask[int(y_waist)][:x_waist_center] == 0)[0]\n",
        "        x_lwb = x_lwb[-1] if len(x_lwb) else 0\n",
        "        x_rwb = np.where(img_mask[int(y_waist)][x_waist_center:] == 0)[0]\n",
        "        x_rwb = x_rwb[0] + x_waist_center if len(x_rwb) else len(img_mask[0])\n",
        "        return x_rwb - x_lwb\n",
        "\n",
        "    def Vis(self, img_RGB):\n",
        "      img_keypoints, img_mask = self._detected(img_RGB)\n",
        "\n",
        "      nose, left_ear, right_ear = img_keypoints[0], img_keypoints[4], img_keypoints[3]\n",
        "      left_shoulder, right_shoulder = img_keypoints[6], img_keypoints[5]\n",
        "      left_hip, right_hip = img_keypoints[12], img_keypoints[11]\n",
        "      left_knee, right_knee = img_keypoints[14], img_keypoints[13]\n",
        "\n",
        "      center_shoulder = (left_shoulder + right_shoulder) / 2\n",
        "      y_hip = (left_hip[1] + right_hip[1]) / 2\n",
        "      y_waist = y_hip * 2 / 3 + (nose[1] + center_shoulder[1]) / 6\n",
        "      left_thigh = (left_knee + left_hip) / 2\n",
        "      right_thigh = (right_knee + right_hip) / 2\n",
        "\n",
        "      img = img_RGB.copy()\n",
        "      for point in [nose, left_ear, right_ear, left_shoulder, right_shoulder, left_hip, right_hip, left_knee, right_knee, center_shoulder, left_thigh, right_thigh]:\n",
        "          cv2.circle(img, (int(point[0]), int(point[1])), 5, (0, 255, 0), -1)\n",
        "\n",
        "      plt.figure(figsize=(6, 10))\n",
        "      plt.imshow(img)\n",
        "      plt.axis(\"off\")\n",
        "      plt.title(\"keypts vis\")\n",
        "      plt.show()\n",
        "    def Vis_measurements(self, img_RGB):\n",
        "      img_keypoints, img_mask = self._detected(img_RGB)\n",
        "      plt.imshow(img_mask, cmap=\"gray\")\n",
        "      plt.title(\"Mask vis\")\n",
        "      plt.show()\n",
        "      left_shoulder, right_shoulder = img_keypoints[6], img_keypoints[5]\n",
        "      left_hip, right_hip = img_keypoints[12], img_keypoints[11]\n",
        "      left_knee, right_knee = img_keypoints[14], img_keypoints[13]\n",
        "\n",
        "      center_shoulder = (left_shoulder + right_shoulder) / 2\n",
        "      y_hip = (left_hip[1] + right_hip[1]) / 2\n",
        "      y_waist = y_hip * 2 / 3 + (img_keypoints[0][1] + center_shoulder[1]) / 6\n",
        "      left_thigh = (left_knee + left_hip) / 2\n",
        "      right_thigh = (right_knee + right_hip) / 2\n",
        "\n",
        "      waist_width = self.waist_width_estimate(center_shoulder, y_waist, img_mask)\n",
        "      hip_width = self.hip_width_estimate(center_shoulder, y_hip, img_mask)\n",
        "      thigh_width = self.thigh_width_estimate(left_thigh, right_thigh, img_mask)\n",
        "\n",
        "      img = img_RGB.copy()\n",
        "      cv2.line(img, (int(center_shoulder[0] - waist_width / 2), int(y_waist)),\n",
        "                    (int(center_shoulder[0] + waist_width / 2), int(y_waist)), (255, 0, 0), 3)\n",
        "      cv2.line(img, (int(center_shoulder[0] - hip_width / 2), int(y_hip)),\n",
        "                    (int(center_shoulder[0] + hip_width / 2), int(y_hip)), (0, 255, 0), 3)\n",
        "      cv2.line(img, (int(left_thigh[0]), int(left_thigh[1])),\n",
        "                    (int(right_thigh[0]), int(right_thigh[1])), (0, 0, 255), 3)\n",
        "\n",
        "      plt.figure(figsize=(6, 10))\n",
        "      plt.imshow(img)\n",
        "      plt.axis(\"off\")\n",
        "      plt.title(\"wasit, hip, thigh\")\n",
        "      plt.show()\n",
        "    def visualize_keypoints(self, img_RGB):\n",
        "        #\n",
        "        img_keypoints, img_mask = self._detected(img_RGB)\n",
        "        nose, left_eye, right_eye, left_ear, right_ear = img_keypoints[0], img_keypoints[1], img_keypoints[2], img_keypoints[3], img_keypoints[4]\n",
        "        left_shoulder, right_shoulder = img_keypoints[5], img_keypoints[6]\n",
        "        left_elbow, right_elbow = img_keypoints[7], img_keypoints[8]\n",
        "        left_wrist, right_wrist = img_keypoints[9], img_keypoints[10]\n",
        "        left_hip, right_hip = img_keypoints[11], img_keypoints[12]\n",
        "        left_knee, right_knee = img_keypoints[13], img_keypoints[14]\n",
        "        left_ankle, right_ankle = img_keypoints[15], img_keypoints[16]\n",
        "\n",
        "        img = img_RGB.copy()\n",
        "\n",
        "        for point in img_keypoints:\n",
        "            cv2.circle(img, (int(point[0]), int(point[1])), 5, (0, 255, 0), -1)\n",
        "\n",
        "        arm_points = [left_shoulder, right_shoulder, left_elbow, right_elbow, left_wrist, right_wrist]\n",
        "        for point in arm_points:\n",
        "            cv2.circle(img, (int(point[0]), int(point[1])), 7, (255, 0, 0), -1)\n",
        "\n",
        "        cv2.line(img, (int(left_shoulder[0]), int(left_shoulder[1])), (int(left_elbow[0]), int(left_elbow[1])), (255, 0, 0), 2)\n",
        "        cv2.line(img, (int(left_elbow[0]), int(left_elbow[1])), (int(left_wrist[0]), int(left_wrist[1])), (255, 0, 0), 2)\n",
        "\n",
        "        cv2.line(img, (int(right_shoulder[0]), int(right_shoulder[1])), (int(right_elbow[0]), int(right_elbow[1])), (255, 0, 0), 2)\n",
        "        cv2.line(img, (int(right_elbow[0]), int(right_elbow[1])), (int(right_wrist[0]), int(right_wrist[1])), (255, 0, 0), 2)\n",
        "\n",
        "        plt.figure(figsize=(6, 10))\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(\"arms and other keypoints\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttdX-nQCf_xG"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import random\n",
        "\n",
        "mask_model = \"/content/drive/MyDrive/singleimg models/pose2seg_release.pkl\"\n",
        "keypoints_model = \"COCO-Keypoints/keypoint_rcnn_R_101_FPN_3x.yaml\"\n",
        "P = Image_Processor(mask_model, keypoints_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNl524iFpVPm"
      },
      "outputs": [],
      "source": [
        "import traceback\n",
        "# Example\n",
        "# choose random image and see how those model works\n",
        "image_folder = \"/content/drive/MyDrive/Image_train/\"\n",
        "\n",
        "image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "if not image_files:\n",
        "    print(\"No image files found in the folder!\")\n",
        "else:\n",
        "    random_image = random.choice(image_files)\n",
        "    img_path = os.path.join(image_folder, random_image)\n",
        "\n",
        "    img_e = cv2.imread(img_path)\n",
        "    if img_e is None:\n",
        "        print(f\"Failed to read image: {img_path}\")\n",
        "    else:\n",
        "        print(f\"Handling image: {img_path}\")\n",
        "\n",
        "\n",
        "\n",
        "        try:\n",
        "            # P.Vis_measurements(img_e)\n",
        "            # P.visualize_keypoints(img_e)\n",
        "            F = P.Process(img_e)\n",
        "            values = {\n",
        "                'WSR': float(F.WSR),\n",
        "                'WTR': float(F.WTR),\n",
        "                'WHpR': float(F.WHpR),\n",
        "                'WHdR': float(F.WHdR),\n",
        "                'HpHdR': float(F.HpHdR),\n",
        "                'Area': float(F.Area),\n",
        "                'H2W': float(F.H2W)\n",
        "\n",
        "            }\n",
        "            print(values)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image: {e}\")\n",
        "            print(traceback.format_exc())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29VBNecNowhO"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvpDL6XcxMzn",
        "outputId": "1e58dbae-a416-421a-a907-ff39f8ddb07a"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import re\n",
        "\n",
        "DATASET_PATHS = {\n",
        "    \"train\": \"/content/drive/MyDrive/Image_train/\",\n",
        "    \"val\": \"/content/drive/MyDrive/Image_val/\",\n",
        "    \"train_gaussian_15\": \"/content/drive/MyDrive/Image_train_gaussian_15/\",\n",
        "    \"train_gaussian_30\": \"/content/drive/MyDrive/Image_train_gaussian_30/\",\n",
        "    \"train_rotate_10\": \"/content/drive/MyDrive/Image_train_rotate_10/\",\n",
        "    \"train_rotate_20\": \"/content/drive/MyDrive/Image_train_rotate_20/\",\n",
        "    \"val_gaussian_15\": \"/content/drive/MyDrive/Image_val_gaussian_15/\",\n",
        "    \"val_gaussian_30\": \"/content/drive/MyDrive/Image_val_gaussian_30/\",\n",
        "    \"val_rotate_10\": \"/content/drive/MyDrive/Image_val_rotate_10/\",\n",
        "    \"val_rotate_20\": \"/content/drive/MyDrive/Image_val_rotate_20/\",\n",
        "}\n",
        "\n",
        "CSV_PATHS = {\n",
        "    \"train\": \"/content/drive/MyDrive/Image_train_features.csv\",\n",
        "    \"val\": \"/content/drive/MyDrive/Image_val_features.csv\",\n",
        "    \"train_gaussian_15\": \"/content/drive/MyDrive/Image_train_gaussian_15_features.csv\",\n",
        "    \"train_gaussian_30\": \"/content/drive/MyDrive/Image_train_gaussian_30_features.csv\",\n",
        "    \"train_rotate_10\": \"/content/drive/MyDrive/Image_train_rotate_10_features.csv\",\n",
        "    \"train_rotate_20\": \"/content/drive/MyDrive/Image_train_rotate_20_features.csv\",\n",
        "    \"val_gaussian_15\": \"/content/drive/MyDrive/Image_val_gaussian_15_features.csv\",\n",
        "    \"val_gaussian_30\": \"/content/drive/MyDrive/Image_val_gaussian_30_features.csv\",\n",
        "    \"val_rotate_10\": \"/content/drive/MyDrive/Image_val_rotate_10_features.csv\",\n",
        "    \"val_rotate_20\": \"/content/drive/MyDrive/Image_val_rotate_20_features.csv\",\n",
        "}\n",
        "\n",
        "def extract_features(image_path):\n",
        "    img_e = cv2.imread(image_path)\n",
        "    if img_e is None:\n",
        "        print(f\"Failed to read image: {image_path}\")\n",
        "        return None\n",
        "    F = P.Process(img_e)\n",
        "    anthropometric_features = [\n",
        "        float(F.WSR), float(F.WTR), float(F.WHpR), float(F.WHdR),\n",
        "        float(F.HpHdR), float(F.Area), float(F.H2W)\n",
        "    ]\n",
        "    return anthropometric_features\n",
        "\n",
        "def extract_bmi_from_filename(filename):\n",
        "    match = re.match(r\"\\d+?_([FMfm])_(\\d+?)_(\\d+?)_(\\d+).+\", filename)\n",
        "    if not match:\n",
        "        print(f\"Skipping invalid filename: {filename}\")\n",
        "        return None, None, None\n",
        "    try:\n",
        "        height = int(match.group(3)) / 100000\n",
        "        weight = int(match.group(4)) / 100000\n",
        "        bmi = weight / (height ** 2)\n",
        "        return height, weight, bmi\n",
        "    except ValueError:\n",
        "        print(f\"Error parsing BMI from filename: {filename}\")\n",
        "        return None, None, None\n",
        "\n",
        "BATCH_SIZE = 10\n",
        "\n",
        "def process_dataset(dataset_type):\n",
        "    image_folder = DATASET_PATHS[dataset_type]\n",
        "    output_csv = CSV_PATHS[dataset_type]\n",
        "    image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    total_images = len(image_files)\n",
        "    if total_images == 0:\n",
        "        print(f\"No images found in {image_folder}\")\n",
        "        return\n",
        "    with open(output_csv, mode=\"w\", newline=\"\") as file:\n",
        "        writer = csv.writer(file)\n",
        "        header = [\"Filename\", \"Height\", \"Weight\", \"BMI\"] + [f\"Anthro_{i+1}\" for i in range(7)]\n",
        "        writer.writerow(header)\n",
        "        for batch_start in range(0, total_images, BATCH_SIZE):\n",
        "            batch_files = image_files[batch_start: batch_start + BATCH_SIZE]\n",
        "            batch_results = []\n",
        "            for img_name in batch_files:\n",
        "                img_path = os.path.join(image_folder, img_name)\n",
        "                try:\n",
        "                    height, weight, bmi = extract_bmi_from_filename(img_name)\n",
        "                    if height is None:\n",
        "                        continue\n",
        "                    features = extract_features(img_path)\n",
        "                    if features is None:\n",
        "                        continue\n",
        "                    batch_results.append([img_name, height, weight, bmi] + features)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {img_name}: {e}\")\n",
        "                    continue\n",
        "            writer.writerows(batch_results)\n",
        "            progress = min(batch_start + BATCH_SIZE, total_images)\n",
        "            print(f\"Processed {progress}/{total_images} images in {dataset_type} ({progress/total_images:.0%})\")\n",
        "    print(f\"Feature extraction complete for {dataset_type}! Saved to {output_csv}\")\n",
        "process_dataset(\"train\")\n",
        "process_dataset(\"val\")\n",
        "process_dataset(\"train_gaussian_15\")\n",
        "process_dataset(\"train_gaussian_30\")\n",
        "process_dataset(\"train_rotate_10\")\n",
        "process_dataset(\"train_rotate_20\")\n",
        "process_dataset(\"val_gaussian_15\")\n",
        "process_dataset(\"val_gaussian_30\")\n",
        "process_dataset(\"val_rotate_10\")\n",
        "process_dataset(\"val_rotate_20\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
